{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# DL Mini Project\n",
        "\n",
        "## Submitted By: Ishwant Singh Bhayana(isb5064), Prajna Ravindra Nayak(pn2224), Parth Mehta(pjm9767) "
      ],
      "metadata": {
        "id": "XQPmsJJnUnkP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Initial Setup\n"
      ],
      "metadata": {
        "id": "VufV7VCa5vPB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pt806zah7MNA",
        "outputId": "d8085469-2e06-400c-f528-aea29ab8d4aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torchinfo\n",
            "  Downloading torchinfo-1.7.2-py3-none-any.whl (22 kB)\n",
            "Installing collected packages: torchinfo\n",
            "Successfully installed torchinfo-1.7.2\n"
          ]
        }
      ],
      "source": [
        "!pip install torchinfo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "pPsyE1-EUFLQ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torch.backends.cudnn as cudnn\n",
        "\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from torchinfo import summary"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training data from CIFAR10"
      ],
      "metadata": {
        "id": "8FqzZhOd6pTa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cJ0BsqeMUQOC",
        "outputId": "1619b058-bf4e-4616-abc9-f1185947b515"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==> Preparing data..\n",
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:13<00:00, 12782749.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "best_acc = 0  # start with 0, will update as better acc is achieved\n",
        "start_epoch = 0\n",
        "\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(\n",
        "    root='./data', train=True, download=True, transform=transform_train)\n",
        "trainloader = torch.utils.data.DataLoader(\n",
        "    trainset, batch_size=128, shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(\n",
        "    root='./data', train=False, download=True, transform=transform_test)\n",
        "testloader = torch.utils.data.DataLoader(\n",
        "    testset, batch_size=100, shuffle=False, num_workers=2)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat', 'deer',\n",
        "           'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "\n",
        "# Reference code: https://github.com/kuangliu/pytorch-cifar/blob/master/models/resnet.py"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model"
      ],
      "metadata": {
        "id": "lSoML2P_62Bp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ZOsXuhoGVgok"
      },
      "outputs": [],
      "source": [
        "class Block(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, in_planes, planes, stride=1):\n",
        "        super(Block, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(\n",
        "            in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
        "                               stride=1, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_planes != self.expansion*planes:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_planes, self.expansion*planes,\n",
        "                          kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(self.expansion*planes)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.bn2(self.conv2(out))\n",
        "        out += self.shortcut(x)\n",
        "        out = F.relu(out)\n",
        "        return out\n",
        "\n",
        "class ResNetModel(nn.Module):\n",
        "    def __init__(self, block, num_blocks, strides=[1,2,2,2], num_classes=10):\n",
        "        super(ResNetModel, self).__init__()\n",
        "        self.in_planes = 64\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3,\n",
        "                               stride=1, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=strides[0])\n",
        "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=strides[1])\n",
        "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=strides[2])\n",
        "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=strides[3])\n",
        "        self.linear = nn.Linear(512*block.expansion, num_classes)\n",
        "\n",
        "    def _make_layer(self, block, planes, num_blocks, stride):\n",
        "        if num_blocks > 0:\n",
        "            strides = [stride] + [1]*(num_blocks-1)\n",
        "            layers = []\n",
        "            for stride in strides:\n",
        "                layers.append(block(self.in_planes, planes, stride))\n",
        "                self.in_planes = planes * block.expansion\n",
        "            return nn.Sequential(*layers)\n",
        "        else:\n",
        "            # Use a single convolution layer instead of a residual block when num_blocks is 0\n",
        "            layer =  nn.Sequential(nn.Conv2d(self.in_planes, planes, kernel_size=1,\n",
        "                                stride=stride, padding=1, bias=False),\n",
        "                          nn.BatchNorm2d(planes))\n",
        "            self.in_planes = planes * block.expansion\n",
        "            return layer\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.layer1(out)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = self.layer4(out)\n",
        "        out = F.avg_pool2d(out, 4)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.linear(out)\n",
        "        return out\n",
        "\n",
        "# Reference code: https://github.com/kuangliu/pytorch-cifar/blob/master/models/resnet.py"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training"
      ],
      "metadata": {
        "id": "pnMYddBC7edZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "VvLqssm9VWAL"
      },
      "outputs": [],
      "source": [
        "learning_rate = 0.1\n",
        "\n",
        "# Train\n",
        "def train_one_epoch(net, optimizer, criterion):\n",
        "    \n",
        "    net.train()\n",
        "    train_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for batch_idx, (inputs, labels) in enumerate(trainloader):\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "        \n",
        "        _, predicted = outputs.max(1)\n",
        "        total += labels.size(0)\n",
        "        correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "        \n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {100.*correct/total:.2f}%')\n",
        "\n",
        "    return train_loss, 100.*correct/total\n",
        "\n",
        "\n",
        "# Test\n",
        "def test(net, optimizer, criterion):\n",
        "\n",
        "    global best_acc\n",
        "    net.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "\n",
        "        for batch_idx, (inputs, labels) in enumerate(testloader):\n",
        "\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = net(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            test_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += labels.size(0)\n",
        "            correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "        print(f'\\tTest Loss: {test_loss:.3f} | Test Acc: {100.*correct/total:.2f}%')\n",
        "\n",
        "        return test_loss, 100.*correct/total\n",
        "\n",
        "    #save the checkpoint\n",
        "    acc = 100.*correct/total\n",
        "    if acc > best_acc: #when curr acc is the best yet\n",
        "        state = {\n",
        "            'net': net.state_dict(),\n",
        "            'acc': acc,\n",
        "            'epoch': epoch,\n",
        "        }\n",
        "        if not os.path.isdir('checkpoint'):\n",
        "            os.mkdir('checkpoint')\n",
        "        torch.save(state, './checkpoint/ckpt.pth')\n",
        "        best_acc = acc\n",
        "\n",
        "\n",
        "# Reference code: https://github.com/kuangliu/pytorch-cifar/blob/master/models/resnet.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "CgjOOShzYtRO"
      },
      "outputs": [],
      "source": [
        "EPOCHS = 50\n",
        "\n",
        "def train(net, learning_rate=0.1):\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.SGD(net.parameters(), lr=learning_rate,\n",
        "                        momentum=0.9, weight_decay=5e-4)\n",
        "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=200)\n",
        "\n",
        "    train_accuracy_history = []\n",
        "    train_loss_history = []\n",
        "    test_accuracy_history = []\n",
        "    test_loss_history = []\n",
        "\n",
        "    for epoch in range(EPOCHS):\n",
        "      \n",
        "        print('\\nEpoch: %d' % epoch)\n",
        "        train_loss, train_acc = train_one_epoch(net, optimizer, criterion)\n",
        "        test_loss, test_acc = test(net, optimizer, criterion)\n",
        "\n",
        "        train_accuracy_history.append(train_acc)\n",
        "\n",
        "        train_loss_history.append(train_loss)\n",
        "        test_accuracy_history.append(test_acc)\n",
        "        test_loss_history.append(test_loss)\n",
        "\n",
        "        scheduler.step()\n",
        "\n",
        "    return {'train': (train_loss_history, train_accuracy_history), 'validation': (test_loss_history, test_accuracy_history)}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir ./results"
      ],
      "metadata": {
        "id": "toplUfqx9LMz"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "O52qBU9BoBeB"
      },
      "outputs": [],
      "source": [
        "def save_to_excel(data, table_name):\n",
        "\n",
        "  df = pd.DataFrame(data=data)\n",
        "  df = df.T\n",
        "\n",
        "  df.to_excel(f'./results/{table_name}.xlsx')\n",
        "\n",
        "def parse_results(results, phase, stat='accuracy'):\n",
        "\n",
        "  stats = {}\n",
        "\n",
        "  stat = 1 if stat == 'accuracy' else 0\n",
        "\n",
        "  for key in results.keys():\n",
        "    \n",
        "      avg = np.average(results[key][phase][stat])\n",
        "      max = np.max(results[key][phase][stat])\n",
        "      stats[key] = {'average': avg, 'max': max}\n",
        "\n",
        "  return stats"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Experimenting with parameter sweeps"
      ],
      "metadata": {
        "id": "qVlZQ1pt8SJk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results = {}\n",
        "for layer1_blocks in range(1, 5):\n",
        "  for layer2_blocks in range(1, 4):\n",
        "      for layer3_blocks in range(3):\n",
        "          for layer4_blocks in range(2):\n",
        "            num_blocks = [layer1_blocks, layer2_blocks, layer3_blocks, layer4_blocks]\n",
        "            net = ResNetModel(Block, num_blocks)\n",
        "            net = net.to(device)\n",
        "            if device == 'cuda':\n",
        "                net = torch.nn.DataParallel(net)\n",
        "                cudnn.benchmark = True\n",
        "\n",
        "            print(f'num_blocks={num_blocks}')\n",
        "\n",
        "            model_summary = summary(net, (128, 3, 32, 32))\n",
        "            n_params = model_summary.trainable_params\n",
        "\n",
        "            if n_params > 5000000:\n",
        "                print(f\"Model has too many parameters ({n_params}), will skip\")\n",
        "                continue\n",
        "            else:\n",
        "                print(f\"Will train model with {n_params}  parameters\")\n",
        "\n",
        "            result = train(net)\n",
        "            results[f'{layer1_blocks}{layer2_blocks}{layer3_blocks}{layer4_blocks}'] = result\n",
        "            \n",
        "            save_to_excel(parse_results(results, 'validation'), 'WIP_block_num_results_val')\n",
        "            save_to_excel(parse_results(results, 'train'), 'WIP_block_num_results_train')\n",
        "\n",
        "save_to_excel(parse_results(results, 'validation'), 'block_num_results_val')\n",
        "save_to_excel(parse_results(results, 'train'), 'block_num_results_train')"
      ],
      "metadata": {
        "id": "5-W5sVK-8Zo7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "924dc38c-5038-4a7f-a374-c576e0f03e04"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "num_blocks=[1, 1, 0, 0]\n",
            "Will train model with 476490  parameters\n",
            "\n",
            "Epoch: 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/torchinfo/torchinfo.py:477: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  action_fn=lambda data: sys.getsizeof(data.storage()),\n",
            "/usr/local/lib/python3.9/dist-packages/torch/storage.py:665: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  return super().__sizeof__() + self.nbytes()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss: 683.527 | Train Acc: 34.18%\n",
            "\tTest Loss: 158.107 | Test Acc: 41.91%\n",
            "\n",
            "Epoch: 1\n",
            "\tTrain Loss: 561.566 | Train Acc: 47.55%\n",
            "\tTest Loss: 139.102 | Test Acc: 49.33%\n",
            "\n",
            "Epoch: 2\n",
            "\tTrain Loss: 508.723 | Train Acc: 52.87%\n",
            "\tTest Loss: 130.675 | Test Acc: 53.05%\n",
            "\n",
            "Epoch: 3\n",
            "\tTrain Loss: 472.265 | Train Acc: 56.98%\n",
            "\tTest Loss: 121.175 | Test Acc: 57.22%\n",
            "\n",
            "Epoch: 4\n",
            "\tTrain Loss: 446.528 | Train Acc: 59.15%\n",
            "\tTest Loss: 144.332 | Test Acc: 51.33%\n",
            "\n",
            "Epoch: 5\n",
            "\tTrain Loss: 428.520 | Train Acc: 61.00%\n",
            "\tTest Loss: 103.931 | Test Acc: 63.07%\n",
            "\n",
            "Epoch: 6\n",
            "\tTrain Loss: 410.790 | Train Acc: 62.82%\n",
            "\tTest Loss: 127.526 | Test Acc: 56.23%\n",
            "\n",
            "Epoch: 7\n",
            "\tTrain Loss: 400.428 | Train Acc: 63.80%\n",
            "\tTest Loss: 116.243 | Test Acc: 59.32%\n",
            "\n",
            "Epoch: 8\n",
            "\tTrain Loss: 392.956 | Train Acc: 64.76%\n",
            "\tTest Loss: 145.597 | Test Acc: 52.73%\n",
            "\n",
            "Epoch: 9\n",
            "\tTrain Loss: 383.737 | Train Acc: 65.59%\n",
            "\tTest Loss: 127.416 | Test Acc: 57.66%\n",
            "\n",
            "Epoch: 10\n",
            "\tTrain Loss: 379.558 | Train Acc: 65.92%\n",
            "\tTest Loss: 120.578 | Test Acc: 59.80%\n",
            "\n",
            "Epoch: 11\n",
            "\tTrain Loss: 373.600 | Train Acc: 66.64%\n",
            "\tTest Loss: 123.717 | Test Acc: 57.83%\n",
            "\n",
            "Epoch: 12\n",
            "\tTrain Loss: 363.945 | Train Acc: 67.37%\n",
            "\tTest Loss: 102.360 | Test Acc: 64.71%\n",
            "\n",
            "Epoch: 13\n",
            "\tTrain Loss: 362.435 | Train Acc: 67.77%\n",
            "\tTest Loss: 109.358 | Test Acc: 63.36%\n",
            "\n",
            "Epoch: 14\n",
            "\tTrain Loss: 356.808 | Train Acc: 68.23%\n",
            "\tTest Loss: 120.080 | Test Acc: 60.03%\n",
            "\n",
            "Epoch: 15\n",
            "\tTrain Loss: 356.620 | Train Acc: 68.11%\n",
            "\tTest Loss: 102.818 | Test Acc: 65.24%\n",
            "\n",
            "Epoch: 16\n",
            "\tTrain Loss: 348.525 | Train Acc: 68.87%\n",
            "\tTest Loss: 114.269 | Test Acc: 61.91%\n",
            "\n",
            "Epoch: 17\n",
            "\tTrain Loss: 348.910 | Train Acc: 69.04%\n",
            "\tTest Loss: 102.219 | Test Acc: 63.92%\n",
            "\n",
            "Epoch: 18\n",
            "\tTrain Loss: 347.427 | Train Acc: 69.10%\n",
            "\tTest Loss: 125.765 | Test Acc: 59.19%\n",
            "\n",
            "Epoch: 19\n",
            "\tTrain Loss: 343.829 | Train Acc: 69.56%\n",
            "\tTest Loss: 100.053 | Test Acc: 65.04%\n",
            "\n",
            "Epoch: 20\n",
            "\tTrain Loss: 343.175 | Train Acc: 69.78%\n",
            "\tTest Loss: 119.013 | Test Acc: 60.79%\n",
            "\n",
            "Epoch: 21\n",
            "\tTrain Loss: 337.208 | Train Acc: 70.12%\n",
            "\tTest Loss: 112.599 | Test Acc: 62.42%\n",
            "\n",
            "Epoch: 22\n",
            "\tTrain Loss: 340.460 | Train Acc: 69.87%\n",
            "\tTest Loss: 114.219 | Test Acc: 62.57%\n",
            "\n",
            "Epoch: 23\n",
            "\tTrain Loss: 335.022 | Train Acc: 70.54%\n",
            "\tTest Loss: 93.350 | Test Acc: 68.33%\n",
            "\n",
            "Epoch: 24\n",
            "\tTrain Loss: 332.074 | Train Acc: 70.66%\n",
            "\tTest Loss: 109.113 | Test Acc: 63.08%\n",
            "\n",
            "Epoch: 25\n",
            "\tTrain Loss: 332.250 | Train Acc: 70.47%\n",
            "\tTest Loss: 99.588 | Test Acc: 65.77%\n",
            "\n",
            "Epoch: 26\n",
            "\tTrain Loss: 330.985 | Train Acc: 70.72%\n",
            "\tTest Loss: 108.739 | Test Acc: 63.57%\n",
            "\n",
            "Epoch: 27\n",
            "\tTrain Loss: 330.777 | Train Acc: 70.82%\n",
            "\tTest Loss: 104.668 | Test Acc: 64.09%\n",
            "\n",
            "Epoch: 28\n",
            "\tTrain Loss: 327.947 | Train Acc: 70.97%\n",
            "\tTest Loss: 114.976 | Test Acc: 63.17%\n",
            "\n",
            "Epoch: 29\n",
            "\tTrain Loss: 329.556 | Train Acc: 70.91%\n",
            "\tTest Loss: 96.605 | Test Acc: 66.66%\n",
            "\n",
            "Epoch: 30\n",
            "\tTrain Loss: 324.568 | Train Acc: 71.28%\n",
            "\tTest Loss: 84.660 | Test Acc: 70.51%\n",
            "\n",
            "Epoch: 31\n",
            "\tTrain Loss: 324.013 | Train Acc: 71.32%\n",
            "\tTest Loss: 113.369 | Test Acc: 62.85%\n",
            "\n",
            "Epoch: 32\n",
            "\tTrain Loss: 326.642 | Train Acc: 71.01%\n",
            "\tTest Loss: 94.964 | Test Acc: 68.45%\n",
            "\n",
            "Epoch: 33\n",
            "\tTrain Loss: 324.373 | Train Acc: 71.23%\n",
            "\tTest Loss: 115.504 | Test Acc: 61.68%\n",
            "\n",
            "Epoch: 34\n",
            "\tTrain Loss: 320.740 | Train Acc: 71.57%\n",
            "\tTest Loss: 95.818 | Test Acc: 67.06%\n",
            "\n",
            "Epoch: 35\n",
            "\tTrain Loss: 320.657 | Train Acc: 71.55%\n",
            "\tTest Loss: 97.359 | Test Acc: 67.13%\n",
            "\n",
            "Epoch: 36\n",
            "\tTrain Loss: 320.112 | Train Acc: 71.81%\n",
            "\tTest Loss: 102.147 | Test Acc: 65.49%\n",
            "\n",
            "Epoch: 37\n",
            "\tTrain Loss: 319.123 | Train Acc: 71.63%\n",
            "\tTest Loss: 93.684 | Test Acc: 68.57%\n",
            "\n",
            "Epoch: 38\n",
            "\tTrain Loss: 316.314 | Train Acc: 71.69%\n",
            "\tTest Loss: 110.175 | Test Acc: 63.49%\n",
            "\n",
            "Epoch: 39\n",
            "\tTrain Loss: 319.366 | Train Acc: 71.88%\n",
            "\tTest Loss: 127.310 | Test Acc: 60.14%\n",
            "\n",
            "Epoch: 40\n",
            "\tTrain Loss: 318.828 | Train Acc: 71.77%\n",
            "\tTest Loss: 88.861 | Test Acc: 69.28%\n",
            "\n",
            "Epoch: 41\n",
            "\tTrain Loss: 315.598 | Train Acc: 72.03%\n",
            "\tTest Loss: 123.490 | Test Acc: 60.98%\n",
            "\n",
            "Epoch: 42\n",
            "\tTrain Loss: 314.496 | Train Acc: 72.24%\n",
            "\tTest Loss: 115.859 | Test Acc: 63.00%\n",
            "\n",
            "Epoch: 43\n",
            "\tTrain Loss: 314.711 | Train Acc: 72.17%\n",
            "\tTest Loss: 108.596 | Test Acc: 64.40%\n",
            "\n",
            "Epoch: 44\n",
            "\tTrain Loss: 312.382 | Train Acc: 72.36%\n",
            "\tTest Loss: 122.093 | Test Acc: 61.63%\n",
            "\n",
            "Epoch: 45\n",
            "\tTrain Loss: 310.591 | Train Acc: 72.40%\n",
            "\tTest Loss: 90.430 | Test Acc: 69.81%\n",
            "\n",
            "Epoch: 46\n",
            "\tTrain Loss: 312.081 | Train Acc: 72.52%\n",
            "\tTest Loss: 87.993 | Test Acc: 70.51%\n",
            "\n",
            "Epoch: 47\n",
            "\tTrain Loss: 309.262 | Train Acc: 72.63%\n",
            "\tTest Loss: 96.533 | Test Acc: 68.48%\n",
            "\n",
            "Epoch: 48\n",
            "\tTrain Loss: 309.891 | Train Acc: 72.55%\n",
            "\tTest Loss: 106.656 | Test Acc: 62.85%\n",
            "\n",
            "Epoch: 49\n",
            "\tTrain Loss: 310.693 | Train Acc: 72.48%\n",
            "\tTest Loss: 93.249 | Test Acc: 67.87%\n",
            "num_blocks=[1, 1, 0, 1]\n",
            "Will train model with 4017482  parameters\n",
            "\n",
            "Epoch: 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/torchinfo/torchinfo.py:477: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  action_fn=lambda data: sys.getsizeof(data.storage()),\n",
            "/usr/local/lib/python3.9/dist-packages/torch/storage.py:665: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  return super().__sizeof__() + self.nbytes()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss: 598.101 | Train Acc: 43.72%\n",
            "\tTest Loss: 133.946 | Test Acc: 53.27%\n",
            "\n",
            "Epoch: 1\n",
            "\tTrain Loss: 428.216 | Train Acc: 60.75%\n",
            "\tTest Loss: 104.126 | Test Acc: 62.17%\n",
            "\n",
            "Epoch: 2\n",
            "\tTrain Loss: 353.731 | Train Acc: 67.92%\n",
            "\tTest Loss: 89.714 | Test Acc: 69.11%\n",
            "\n",
            "Epoch: 3\n",
            "\tTrain Loss: 306.321 | Train Acc: 72.39%\n",
            "\tTest Loss: 94.685 | Test Acc: 68.85%\n",
            "\n",
            "Epoch: 4\n",
            "\tTrain Loss: 276.106 | Train Acc: 75.70%\n",
            "\tTest Loss: 95.604 | Test Acc: 69.34%\n",
            "\n",
            "Epoch: 5\n",
            "\tTrain Loss: 257.245 | Train Acc: 77.18%\n",
            "\tTest Loss: 85.280 | Test Acc: 71.10%\n",
            "\n",
            "Epoch: 6\n",
            "\tTrain Loss: 244.435 | Train Acc: 78.41%\n",
            "\tTest Loss: 84.721 | Test Acc: 71.88%\n",
            "\n",
            "Epoch: 7\n",
            "\tTrain Loss: 235.258 | Train Acc: 79.12%\n",
            "\tTest Loss: 62.280 | Test Acc: 78.12%\n",
            "\n",
            "Epoch: 8\n",
            "\tTrain Loss: 230.589 | Train Acc: 79.41%\n",
            "\tTest Loss: 64.203 | Test Acc: 78.22%\n",
            "\n",
            "Epoch: 9\n",
            "\tTrain Loss: 224.092 | Train Acc: 80.23%\n",
            "\tTest Loss: 76.534 | Test Acc: 74.15%\n",
            "\n",
            "Epoch: 10\n",
            "\tTrain Loss: 216.944 | Train Acc: 81.00%\n",
            "\tTest Loss: 75.627 | Test Acc: 74.18%\n",
            "\n",
            "Epoch: 11\n",
            "\tTrain Loss: 213.986 | Train Acc: 80.97%\n",
            "\tTest Loss: 72.569 | Test Acc: 75.34%\n",
            "\n",
            "Epoch: 12\n",
            "\tTrain Loss: 208.241 | Train Acc: 81.80%\n",
            "\tTest Loss: 67.689 | Test Acc: 77.75%\n",
            "\n",
            "Epoch: 13\n",
            "\tTrain Loss: 201.450 | Train Acc: 82.30%\n",
            "\tTest Loss: 89.738 | Test Acc: 72.41%\n",
            "\n",
            "Epoch: 14\n",
            "\tTrain Loss: 202.224 | Train Acc: 82.22%\n",
            "\tTest Loss: 68.672 | Test Acc: 77.46%\n",
            "\n",
            "Epoch: 15\n",
            "\tTrain Loss: 200.496 | Train Acc: 82.40%\n",
            "\tTest Loss: 77.729 | Test Acc: 75.06%\n",
            "\n",
            "Epoch: 16\n",
            "\tTrain Loss: 195.496 | Train Acc: 82.80%\n",
            "\tTest Loss: 67.997 | Test Acc: 78.46%\n",
            "\n",
            "Epoch: 17\n",
            "\tTrain Loss: 194.485 | Train Acc: 82.80%\n",
            "\tTest Loss: 58.535 | Test Acc: 80.02%\n",
            "\n",
            "Epoch: 18\n",
            "\tTrain Loss: 191.473 | Train Acc: 83.16%\n",
            "\tTest Loss: 62.288 | Test Acc: 79.52%\n",
            "\n",
            "Epoch: 19\n",
            "\tTrain Loss: 191.673 | Train Acc: 83.20%\n",
            "\tTest Loss: 80.579 | Test Acc: 74.47%\n",
            "\n",
            "Epoch: 20\n",
            "\tTrain Loss: 190.055 | Train Acc: 83.29%\n",
            "\tTest Loss: 62.467 | Test Acc: 79.29%\n",
            "\n",
            "Epoch: 21\n",
            "\tTrain Loss: 188.494 | Train Acc: 83.48%\n",
            "\tTest Loss: 69.989 | Test Acc: 76.36%\n",
            "\n",
            "Epoch: 22\n",
            "\tTrain Loss: 188.133 | Train Acc: 83.43%\n",
            "\tTest Loss: 67.608 | Test Acc: 77.91%\n",
            "\n",
            "Epoch: 23\n",
            "\tTrain Loss: 184.584 | Train Acc: 83.74%\n",
            "\tTest Loss: 70.448 | Test Acc: 77.50%\n",
            "\n",
            "Epoch: 24\n",
            "\tTrain Loss: 184.751 | Train Acc: 83.96%\n",
            "\tTest Loss: 67.531 | Test Acc: 78.10%\n",
            "\n",
            "Epoch: 25\n",
            "\tTrain Loss: 183.024 | Train Acc: 84.01%\n",
            "\tTest Loss: 65.685 | Test Acc: 78.01%\n",
            "\n",
            "Epoch: 26\n",
            "\tTrain Loss: 183.566 | Train Acc: 83.91%\n",
            "\tTest Loss: 73.654 | Test Acc: 76.15%\n",
            "\n",
            "Epoch: 27\n",
            "\tTrain Loss: 180.193 | Train Acc: 84.05%\n",
            "\tTest Loss: 79.717 | Test Acc: 74.53%\n",
            "\n",
            "Epoch: 28\n",
            "\tTrain Loss: 179.931 | Train Acc: 84.20%\n",
            "\tTest Loss: 55.774 | Test Acc: 80.81%\n",
            "\n",
            "Epoch: 29\n",
            "\tTrain Loss: 178.293 | Train Acc: 84.26%\n",
            "\tTest Loss: 102.797 | Test Acc: 68.49%\n",
            "\n",
            "Epoch: 30\n",
            "\tTrain Loss: 176.643 | Train Acc: 84.57%\n",
            "\tTest Loss: 61.618 | Test Acc: 78.84%\n",
            "\n",
            "Epoch: 31\n",
            "\tTrain Loss: 179.024 | Train Acc: 84.30%\n",
            "\tTest Loss: 62.194 | Test Acc: 79.36%\n",
            "\n",
            "Epoch: 32\n",
            "\tTrain Loss: 174.952 | Train Acc: 84.70%\n",
            "\tTest Loss: 68.903 | Test Acc: 77.65%\n",
            "\n",
            "Epoch: 33\n",
            "\tTrain Loss: 177.207 | Train Acc: 84.41%\n",
            "\tTest Loss: 65.032 | Test Acc: 78.71%\n",
            "\n",
            "Epoch: 34\n",
            "\tTrain Loss: 176.476 | Train Acc: 84.50%\n",
            "\tTest Loss: 51.720 | Test Acc: 82.02%\n",
            "\n",
            "Epoch: 35\n",
            "\tTrain Loss: 174.958 | Train Acc: 84.63%\n",
            "\tTest Loss: 53.633 | Test Acc: 81.46%\n",
            "\n",
            "Epoch: 36\n",
            "\tTrain Loss: 172.773 | Train Acc: 84.75%\n",
            "\tTest Loss: 66.543 | Test Acc: 78.48%\n",
            "\n",
            "Epoch: 37\n",
            "\tTrain Loss: 170.681 | Train Acc: 85.06%\n",
            "\tTest Loss: 69.366 | Test Acc: 76.81%\n",
            "\n",
            "Epoch: 38\n",
            "\tTrain Loss: 171.955 | Train Acc: 84.92%\n",
            "\tTest Loss: 61.860 | Test Acc: 79.60%\n",
            "\n",
            "Epoch: 39\n",
            "\tTrain Loss: 170.723 | Train Acc: 85.02%\n",
            "\tTest Loss: 55.743 | Test Acc: 82.18%\n",
            "\n",
            "Epoch: 40\n",
            "\tTrain Loss: 169.328 | Train Acc: 85.08%\n",
            "\tTest Loss: 51.448 | Test Acc: 82.81%\n",
            "\n",
            "Epoch: 41\n",
            "\tTrain Loss: 167.579 | Train Acc: 85.15%\n",
            "\tTest Loss: 55.871 | Test Acc: 80.94%\n",
            "\n",
            "Epoch: 42\n",
            "\tTrain Loss: 170.107 | Train Acc: 84.92%\n",
            "\tTest Loss: 57.020 | Test Acc: 80.20%\n",
            "\n",
            "Epoch: 43\n",
            "\tTrain Loss: 167.237 | Train Acc: 85.34%\n",
            "\tTest Loss: 70.447 | Test Acc: 77.90%\n",
            "\n",
            "Epoch: 44\n",
            "\tTrain Loss: 167.646 | Train Acc: 85.26%\n",
            "\tTest Loss: 67.649 | Test Acc: 78.40%\n",
            "\n",
            "Epoch: 45\n",
            "\tTrain Loss: 166.999 | Train Acc: 85.49%\n",
            "\tTest Loss: 64.009 | Test Acc: 80.35%\n",
            "\n",
            "Epoch: 46\n",
            "\tTrain Loss: 165.251 | Train Acc: 85.29%\n",
            "\tTest Loss: 66.816 | Test Acc: 76.93%\n",
            "\n",
            "Epoch: 47\n",
            "\tTrain Loss: 163.942 | Train Acc: 85.79%\n",
            "\tTest Loss: 62.029 | Test Acc: 79.60%\n",
            "\n",
            "Epoch: 48\n",
            "\tTrain Loss: 164.351 | Train Acc: 85.65%\n",
            "\tTest Loss: 45.865 | Test Acc: 84.35%\n",
            "\n",
            "Epoch: 49\n",
            "\tTrain Loss: 163.065 | Train Acc: 85.81%\n",
            "\tTest Loss: 87.611 | Test Acc: 74.39%\n",
            "num_blocks=[1, 1, 1, 0]\n",
            "Will train model with 1362250  parameters\n",
            "\n",
            "Epoch: 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/torchinfo/torchinfo.py:477: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  action_fn=lambda data: sys.getsizeof(data.storage()),\n",
            "/usr/local/lib/python3.9/dist-packages/torch/storage.py:665: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  return super().__sizeof__() + self.nbytes()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss: 622.814 | Train Acc: 41.02%\n",
            "\tTest Loss: 135.058 | Test Acc: 52.20%\n",
            "\n",
            "Epoch: 1\n",
            "\tTrain Loss: 449.839 | Train Acc: 58.49%\n",
            "\tTest Loss: 117.706 | Test Acc: 59.67%\n",
            "\n",
            "Epoch: 2\n",
            "\tTrain Loss: 365.490 | Train Acc: 67.27%\n",
            "\tTest Loss: 105.401 | Test Acc: 63.24%\n",
            "\n",
            "Epoch: 3\n",
            "\tTrain Loss: 310.818 | Train Acc: 72.00%\n",
            "\tTest Loss: 87.263 | Test Acc: 70.53%\n",
            "\n",
            "Epoch: 4\n",
            "\tTrain Loss: 280.469 | Train Acc: 75.13%\n",
            "\tTest Loss: 118.657 | Test Acc: 63.45%\n",
            "\n",
            "Epoch: 5\n",
            "\tTrain Loss: 259.186 | Train Acc: 77.06%\n",
            "\tTest Loss: 85.467 | Test Acc: 71.58%\n",
            "\n",
            "Epoch: 6\n",
            "\tTrain Loss: 247.194 | Train Acc: 78.16%\n",
            "\tTest Loss: 77.643 | Test Acc: 74.61%\n",
            "\n",
            "Epoch: 7\n",
            "\tTrain Loss: 235.251 | Train Acc: 79.22%\n",
            "\tTest Loss: 73.305 | Test Acc: 75.19%\n",
            "\n",
            "Epoch: 8\n",
            "\tTrain Loss: 225.079 | Train Acc: 80.27%\n",
            "\tTest Loss: 63.591 | Test Acc: 77.54%\n",
            "\n",
            "Epoch: 9\n",
            "\tTrain Loss: 218.125 | Train Acc: 80.86%\n",
            "\tTest Loss: 100.513 | Test Acc: 69.14%\n",
            "\n",
            "Epoch: 10\n",
            "\tTrain Loss: 211.258 | Train Acc: 81.33%\n",
            "\tTest Loss: 61.207 | Test Acc: 79.24%\n",
            "\n",
            "Epoch: 11\n",
            "\tTrain Loss: 211.151 | Train Acc: 81.30%\n",
            "\tTest Loss: 78.093 | Test Acc: 76.06%\n",
            "\n",
            "Epoch: 12\n",
            "\tTrain Loss: 201.794 | Train Acc: 82.27%\n",
            "\tTest Loss: 85.810 | Test Acc: 73.40%\n",
            "\n",
            "Epoch: 13\n",
            "\tTrain Loss: 198.664 | Train Acc: 82.55%\n",
            "\tTest Loss: 67.416 | Test Acc: 78.09%\n",
            "\n",
            "Epoch: 14\n",
            "\tTrain Loss: 197.353 | Train Acc: 82.61%\n",
            "\tTest Loss: 65.608 | Test Acc: 78.10%\n",
            "\n",
            "Epoch: 15\n",
            "\tTrain Loss: 192.461 | Train Acc: 83.12%\n",
            "\tTest Loss: 67.930 | Test Acc: 78.60%\n",
            "\n",
            "Epoch: 16\n",
            "\tTrain Loss: 190.724 | Train Acc: 83.22%\n",
            "\tTest Loss: 53.111 | Test Acc: 82.27%\n",
            "\n",
            "Epoch: 17\n",
            "\tTrain Loss: 190.080 | Train Acc: 83.14%\n",
            "\tTest Loss: 67.621 | Test Acc: 77.19%\n",
            "\n",
            "Epoch: 18\n",
            "\tTrain Loss: 186.776 | Train Acc: 83.55%\n",
            "\tTest Loss: 61.563 | Test Acc: 79.17%\n",
            "\n",
            "Epoch: 19\n",
            "\tTrain Loss: 187.220 | Train Acc: 83.56%\n",
            "\tTest Loss: 64.552 | Test Acc: 79.36%\n",
            "\n",
            "Epoch: 20\n",
            "\tTrain Loss: 182.440 | Train Acc: 83.92%\n",
            "\tTest Loss: 61.742 | Test Acc: 79.11%\n",
            "\n",
            "Epoch: 21\n",
            "\tTrain Loss: 181.514 | Train Acc: 84.15%\n",
            "\tTest Loss: 55.152 | Test Acc: 81.78%\n",
            "\n",
            "Epoch: 22\n",
            "\tTrain Loss: 179.175 | Train Acc: 84.37%\n",
            "\tTest Loss: 52.741 | Test Acc: 82.01%\n",
            "\n",
            "Epoch: 23\n",
            "\tTrain Loss: 180.839 | Train Acc: 84.12%\n",
            "\tTest Loss: 68.919 | Test Acc: 77.59%\n",
            "\n",
            "Epoch: 24\n",
            "\tTrain Loss: 177.689 | Train Acc: 84.50%\n",
            "\tTest Loss: 72.275 | Test Acc: 77.81%\n",
            "\n",
            "Epoch: 25\n",
            "\tTrain Loss: 174.869 | Train Acc: 84.72%\n",
            "\tTest Loss: 63.199 | Test Acc: 79.23%\n",
            "\n",
            "Epoch: 26\n",
            "\tTrain Loss: 175.917 | Train Acc: 84.52%\n",
            "\tTest Loss: 63.743 | Test Acc: 79.37%\n",
            "\n",
            "Epoch: 27\n",
            "\tTrain Loss: 174.457 | Train Acc: 84.85%\n",
            "\tTest Loss: 68.542 | Test Acc: 77.68%\n",
            "\n",
            "Epoch: 28\n",
            "\tTrain Loss: 173.742 | Train Acc: 84.71%\n",
            "\tTest Loss: 72.409 | Test Acc: 76.91%\n",
            "\n",
            "Epoch: 29\n",
            "\tTrain Loss: 174.836 | Train Acc: 84.72%\n",
            "\tTest Loss: 60.284 | Test Acc: 80.01%\n",
            "\n",
            "Epoch: 30\n",
            "\tTrain Loss: 173.294 | Train Acc: 84.70%\n",
            "\tTest Loss: 56.231 | Test Acc: 81.38%\n",
            "\n",
            "Epoch: 31\n",
            "\tTrain Loss: 171.575 | Train Acc: 84.89%\n",
            "\tTest Loss: 87.707 | Test Acc: 73.74%\n",
            "\n",
            "Epoch: 32\n",
            "\tTrain Loss: 171.148 | Train Acc: 85.09%\n",
            "\tTest Loss: 57.553 | Test Acc: 81.50%\n",
            "\n",
            "Epoch: 33\n",
            "\tTrain Loss: 169.176 | Train Acc: 85.02%\n",
            "\tTest Loss: 68.553 | Test Acc: 78.18%\n",
            "\n",
            "Epoch: 34\n",
            "\tTrain Loss: 167.125 | Train Acc: 85.38%\n",
            "\tTest Loss: 65.342 | Test Acc: 79.59%\n",
            "\n",
            "Epoch: 35\n",
            "\tTrain Loss: 165.972 | Train Acc: 85.51%\n",
            "\tTest Loss: 53.069 | Test Acc: 82.40%\n",
            "\n",
            "Epoch: 36\n",
            "\tTrain Loss: 166.875 | Train Acc: 85.29%\n",
            "\tTest Loss: 55.358 | Test Acc: 81.16%\n",
            "\n",
            "Epoch: 37\n",
            "\tTrain Loss: 166.347 | Train Acc: 85.51%\n",
            "\tTest Loss: 65.938 | Test Acc: 77.68%\n",
            "\n",
            "Epoch: 38\n",
            "\tTrain Loss: 164.770 | Train Acc: 85.47%\n",
            "\tTest Loss: 67.772 | Test Acc: 79.63%\n",
            "\n",
            "Epoch: 39\n",
            "\tTrain Loss: 165.069 | Train Acc: 85.58%\n",
            "\tTest Loss: 80.103 | Test Acc: 75.62%\n",
            "\n",
            "Epoch: 40\n",
            "\tTrain Loss: 166.264 | Train Acc: 85.35%\n",
            "\tTest Loss: 71.787 | Test Acc: 77.74%\n",
            "\n",
            "Epoch: 41\n",
            "\tTrain Loss: 163.463 | Train Acc: 85.67%\n",
            "\tTest Loss: 57.905 | Test Acc: 81.81%\n",
            "\n",
            "Epoch: 42\n",
            "\tTrain Loss: 160.920 | Train Acc: 85.89%\n",
            "\tTest Loss: 53.512 | Test Acc: 82.62%\n",
            "\n",
            "Epoch: 43\n",
            "\tTrain Loss: 162.221 | Train Acc: 85.80%\n",
            "\tTest Loss: 60.500 | Test Acc: 80.23%\n",
            "\n",
            "Epoch: 44\n",
            "\tTrain Loss: 160.538 | Train Acc: 86.02%\n",
            "\tTest Loss: 56.713 | Test Acc: 81.00%\n",
            "\n",
            "Epoch: 45\n",
            "\tTrain Loss: 161.527 | Train Acc: 85.91%\n",
            "\tTest Loss: 52.174 | Test Acc: 82.63%\n",
            "\n",
            "Epoch: 46\n",
            "\tTrain Loss: 157.089 | Train Acc: 86.18%\n",
            "\tTest Loss: 61.664 | Test Acc: 80.39%\n",
            "\n",
            "Epoch: 47\n",
            "\tTrain Loss: 158.251 | Train Acc: 86.10%\n",
            "\tTest Loss: 49.976 | Test Acc: 82.68%\n",
            "\n",
            "Epoch: 48\n",
            "\tTrain Loss: 157.036 | Train Acc: 86.14%\n",
            "\tTest Loss: 70.357 | Test Acc: 79.33%\n",
            "\n",
            "Epoch: 49\n",
            "\tTrain Loss: 157.595 | Train Acc: 86.25%\n",
            "\tTest Loss: 56.425 | Test Acc: 81.34%\n",
            "num_blocks=[1, 1, 1, 1]\n",
            "Will train model with 4903242  parameters\n",
            "\n",
            "Epoch: 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/torchinfo/torchinfo.py:477: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  action_fn=lambda data: sys.getsizeof(data.storage()),\n",
            "/usr/local/lib/python3.9/dist-packages/torch/storage.py:665: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  return super().__sizeof__() + self.nbytes()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss: 616.142 | Train Acc: 41.88%\n",
            "\tTest Loss: 127.034 | Test Acc: 54.21%\n",
            "\n",
            "Epoch: 1\n",
            "\tTrain Loss: 426.041 | Train Acc: 60.89%\n",
            "\tTest Loss: 118.225 | Test Acc: 60.95%\n",
            "\n",
            "Epoch: 2\n",
            "\tTrain Loss: 336.903 | Train Acc: 69.24%\n",
            "\tTest Loss: 88.048 | Test Acc: 69.23%\n",
            "\n",
            "Epoch: 3\n",
            "\tTrain Loss: 281.702 | Train Acc: 74.77%\n",
            "\tTest Loss: 81.769 | Test Acc: 72.12%\n",
            "\n",
            "Epoch: 4\n",
            "\tTrain Loss: 247.335 | Train Acc: 77.90%\n",
            "\tTest Loss: 79.932 | Test Acc: 72.41%\n",
            "\n",
            "Epoch: 5\n",
            "\tTrain Loss: 226.572 | Train Acc: 79.95%\n",
            "\tTest Loss: 76.077 | Test Acc: 75.30%\n",
            "\n",
            "Epoch: 6\n",
            "\tTrain Loss: 210.751 | Train Acc: 81.32%\n",
            "\tTest Loss: 69.897 | Test Acc: 77.39%\n",
            "\n",
            "Epoch: 7\n",
            "\tTrain Loss: 202.520 | Train Acc: 82.18%\n",
            "\tTest Loss: 60.085 | Test Acc: 80.26%\n",
            "\n",
            "Epoch: 8\n",
            "\tTrain Loss: 193.150 | Train Acc: 82.97%\n",
            "\tTest Loss: 70.808 | Test Acc: 76.55%\n",
            "\n",
            "Epoch: 9\n",
            "\tTrain Loss: 187.416 | Train Acc: 83.49%\n",
            "\tTest Loss: 56.240 | Test Acc: 81.31%\n",
            "\n",
            "Epoch: 10\n",
            "\tTrain Loss: 179.714 | Train Acc: 84.14%\n",
            "\tTest Loss: 64.303 | Test Acc: 78.96%\n",
            "\n",
            "Epoch: 11\n",
            "\tTrain Loss: 173.472 | Train Acc: 84.68%\n",
            "\tTest Loss: 82.920 | Test Acc: 74.26%\n",
            "\n",
            "Epoch: 12\n",
            "\tTrain Loss: 170.734 | Train Acc: 84.99%\n",
            "\tTest Loss: 72.976 | Test Acc: 76.19%\n",
            "\n",
            "Epoch: 13\n",
            "\tTrain Loss: 167.931 | Train Acc: 85.21%\n",
            "\tTest Loss: 72.221 | Test Acc: 76.51%\n",
            "\n",
            "Epoch: 14\n",
            "\tTrain Loss: 165.788 | Train Acc: 85.37%\n",
            "\tTest Loss: 59.311 | Test Acc: 79.19%\n",
            "\n",
            "Epoch: 15\n",
            "\tTrain Loss: 161.898 | Train Acc: 85.72%\n",
            "\tTest Loss: 58.825 | Test Acc: 80.94%\n",
            "\n",
            "Epoch: 16\n",
            "\tTrain Loss: 158.664 | Train Acc: 86.20%\n",
            "\tTest Loss: 57.010 | Test Acc: 81.34%\n",
            "\n",
            "Epoch: 17\n",
            "\tTrain Loss: 157.167 | Train Acc: 86.11%\n",
            "\tTest Loss: 59.039 | Test Acc: 80.18%\n",
            "\n",
            "Epoch: 18\n",
            "\tTrain Loss: 154.214 | Train Acc: 86.39%\n",
            "\tTest Loss: 62.043 | Test Acc: 80.59%\n",
            "\n",
            "Epoch: 19\n",
            "\tTrain Loss: 151.281 | Train Acc: 86.73%\n",
            "\tTest Loss: 52.956 | Test Acc: 82.46%\n",
            "\n",
            "Epoch: 20\n",
            "\tTrain Loss: 150.342 | Train Acc: 86.90%\n",
            "\tTest Loss: 45.088 | Test Acc: 84.83%\n",
            "\n",
            "Epoch: 21\n",
            "\tTrain Loss: 147.739 | Train Acc: 87.09%\n",
            "\tTest Loss: 46.255 | Test Acc: 84.54%\n",
            "\n",
            "Epoch: 22\n",
            "\tTrain Loss: 146.655 | Train Acc: 87.01%\n",
            "\tTest Loss: 46.604 | Test Acc: 84.85%\n",
            "\n",
            "Epoch: 23\n",
            "\tTrain Loss: 144.179 | Train Acc: 87.31%\n",
            "\tTest Loss: 59.359 | Test Acc: 80.71%\n",
            "\n",
            "Epoch: 24\n",
            "\tTrain Loss: 145.741 | Train Acc: 87.24%\n",
            "\tTest Loss: 51.873 | Test Acc: 82.83%\n",
            "\n",
            "Epoch: 25\n",
            "\tTrain Loss: 144.616 | Train Acc: 87.32%\n",
            "\tTest Loss: 58.178 | Test Acc: 81.67%\n",
            "\n",
            "Epoch: 26\n",
            "\tTrain Loss: 139.536 | Train Acc: 87.84%\n",
            "\tTest Loss: 65.206 | Test Acc: 78.84%\n",
            "\n",
            "Epoch: 27\n",
            "\tTrain Loss: 142.166 | Train Acc: 87.45%\n",
            "\tTest Loss: 45.723 | Test Acc: 84.95%\n",
            "\n",
            "Epoch: 28\n",
            "\tTrain Loss: 141.387 | Train Acc: 87.64%\n",
            "\tTest Loss: 57.825 | Test Acc: 80.94%\n",
            "\n",
            "Epoch: 29\n",
            "\tTrain Loss: 139.390 | Train Acc: 87.68%\n",
            "\tTest Loss: 55.710 | Test Acc: 81.91%\n",
            "\n",
            "Epoch: 30\n",
            "\tTrain Loss: 137.948 | Train Acc: 87.81%\n",
            "\tTest Loss: 53.258 | Test Acc: 82.25%\n",
            "\n",
            "Epoch: 31\n",
            "\tTrain Loss: 136.334 | Train Acc: 88.10%\n",
            "\tTest Loss: 65.659 | Test Acc: 78.63%\n",
            "\n",
            "Epoch: 32\n",
            "\tTrain Loss: 136.813 | Train Acc: 87.96%\n",
            "\tTest Loss: 64.666 | Test Acc: 79.07%\n",
            "\n",
            "Epoch: 33\n",
            "\tTrain Loss: 135.181 | Train Acc: 88.12%\n",
            "\tTest Loss: 53.166 | Test Acc: 83.38%\n",
            "\n",
            "Epoch: 34\n",
            "\tTrain Loss: 134.876 | Train Acc: 87.98%\n",
            "\tTest Loss: 63.025 | Test Acc: 80.65%\n",
            "\n",
            "Epoch: 35\n",
            "\tTrain Loss: 135.076 | Train Acc: 88.13%\n",
            "\tTest Loss: 61.737 | Test Acc: 79.73%\n",
            "\n",
            "Epoch: 36\n",
            "\tTrain Loss: 133.462 | Train Acc: 88.32%\n",
            "\tTest Loss: 45.564 | Test Acc: 84.41%\n",
            "\n",
            "Epoch: 37\n",
            "\tTrain Loss: 130.950 | Train Acc: 88.44%\n",
            "\tTest Loss: 54.412 | Test Acc: 81.91%\n",
            "\n",
            "Epoch: 38\n",
            "\tTrain Loss: 132.129 | Train Acc: 88.38%\n",
            "\tTest Loss: 61.700 | Test Acc: 80.32%\n",
            "\n",
            "Epoch: 39\n",
            "\tTrain Loss: 133.019 | Train Acc: 88.35%\n",
            "\tTest Loss: 53.395 | Test Acc: 82.67%\n",
            "\n",
            "Epoch: 40\n",
            "\tTrain Loss: 132.315 | Train Acc: 88.40%\n",
            "\tTest Loss: 69.345 | Test Acc: 77.98%\n",
            "\n",
            "Epoch: 41\n",
            "\tTrain Loss: 130.369 | Train Acc: 88.63%\n",
            "\tTest Loss: 61.483 | Test Acc: 80.13%\n",
            "\n",
            "Epoch: 42\n",
            "\tTrain Loss: 128.947 | Train Acc: 88.82%\n",
            "\tTest Loss: 55.763 | Test Acc: 82.45%\n",
            "\n",
            "Epoch: 43\n",
            "\tTrain Loss: 130.343 | Train Acc: 88.63%\n",
            "\tTest Loss: 53.079 | Test Acc: 82.43%\n",
            "\n",
            "Epoch: 44\n",
            "\tTrain Loss: 128.059 | Train Acc: 88.70%\n",
            "\tTest Loss: 47.188 | Test Acc: 84.10%\n",
            "\n",
            "Epoch: 45\n",
            "\tTrain Loss: 125.431 | Train Acc: 88.96%\n",
            "\tTest Loss: 55.190 | Test Acc: 82.79%\n",
            "\n",
            "Epoch: 46\n",
            "\tTrain Loss: 128.581 | Train Acc: 88.76%\n",
            "\tTest Loss: 63.008 | Test Acc: 80.52%\n",
            "\n",
            "Epoch: 47\n",
            "\tTrain Loss: 126.289 | Train Acc: 88.68%\n",
            "\tTest Loss: 49.433 | Test Acc: 83.76%\n",
            "\n",
            "Epoch: 48\n",
            "\tTrain Loss: 126.669 | Train Acc: 88.81%\n",
            "\tTest Loss: 55.170 | Test Acc: 82.52%\n",
            "\n",
            "Epoch: 49\n",
            "\tTrain Loss: 124.604 | Train Acc: 88.87%\n",
            "\tTest Loss: 54.224 | Test Acc: 82.44%\n",
            "num_blocks=[1, 1, 2, 0]\n",
            "Will train model with 2542922  parameters\n",
            "\n",
            "Epoch: 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/torchinfo/torchinfo.py:477: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  action_fn=lambda data: sys.getsizeof(data.storage()),\n",
            "/usr/local/lib/python3.9/dist-packages/torch/storage.py:665: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  return super().__sizeof__() + self.nbytes()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss: 617.484 | Train Acc: 41.48%\n",
            "\tTest Loss: 135.670 | Test Acc: 52.33%\n",
            "\n",
            "Epoch: 1\n",
            "\tTrain Loss: 422.867 | Train Acc: 61.43%\n",
            "\tTest Loss: 95.219 | Test Acc: 66.82%\n",
            "\n",
            "Epoch: 2\n",
            "\tTrain Loss: 326.842 | Train Acc: 70.54%\n",
            "\tTest Loss: 95.213 | Test Acc: 69.91%\n",
            "\n",
            "Epoch: 3\n",
            "\tTrain Loss: 271.751 | Train Acc: 75.98%\n",
            "\tTest Loss: 82.118 | Test Acc: 71.90%\n",
            "\n",
            "Epoch: 4\n",
            "\tTrain Loss: 239.941 | Train Acc: 78.84%\n",
            "\tTest Loss: 80.149 | Test Acc: 74.09%\n",
            "\n",
            "Epoch: 5\n",
            "\tTrain Loss: 221.985 | Train Acc: 80.41%\n",
            "\tTest Loss: 72.421 | Test Acc: 76.51%\n",
            "\n",
            "Epoch: 6\n",
            "\tTrain Loss: 210.378 | Train Acc: 81.50%\n",
            "\tTest Loss: 70.097 | Test Acc: 77.13%\n",
            "\n",
            "Epoch: 7\n",
            "\tTrain Loss: 197.689 | Train Acc: 82.66%\n",
            "\tTest Loss: 67.342 | Test Acc: 77.64%\n",
            "\n",
            "Epoch: 8\n",
            "\tTrain Loss: 189.447 | Train Acc: 83.42%\n",
            "\tTest Loss: 83.430 | Test Acc: 73.74%\n",
            "\n",
            "Epoch: 9\n",
            "\tTrain Loss: 182.464 | Train Acc: 84.10%\n",
            "\tTest Loss: 55.527 | Test Acc: 81.85%\n",
            "\n",
            "Epoch: 10\n",
            "\tTrain Loss: 177.455 | Train Acc: 84.44%\n",
            "\tTest Loss: 79.503 | Test Acc: 73.96%\n",
            "\n",
            "Epoch: 11\n",
            "\tTrain Loss: 173.600 | Train Acc: 84.73%\n",
            "\tTest Loss: 68.342 | Test Acc: 77.29%\n",
            "\n",
            "Epoch: 12\n",
            "\tTrain Loss: 169.778 | Train Acc: 84.99%\n",
            "\tTest Loss: 54.037 | Test Acc: 82.36%\n",
            "\n",
            "Epoch: 13\n",
            "\tTrain Loss: 163.485 | Train Acc: 85.72%\n",
            "\tTest Loss: 69.987 | Test Acc: 77.09%\n",
            "\n",
            "Epoch: 14\n",
            "\tTrain Loss: 160.913 | Train Acc: 85.77%\n",
            "\tTest Loss: 50.194 | Test Acc: 83.49%\n",
            "\n",
            "Epoch: 15\n",
            "\tTrain Loss: 158.686 | Train Acc: 85.96%\n",
            "\tTest Loss: 59.642 | Test Acc: 79.81%\n",
            "\n",
            "Epoch: 16\n",
            "\tTrain Loss: 155.088 | Train Acc: 86.36%\n",
            "\tTest Loss: 61.845 | Test Acc: 80.33%\n",
            "\n",
            "Epoch: 17\n",
            "\tTrain Loss: 153.876 | Train Acc: 86.47%\n",
            "\tTest Loss: 52.363 | Test Acc: 82.30%\n",
            "\n",
            "Epoch: 18\n",
            "\tTrain Loss: 152.166 | Train Acc: 86.61%\n",
            "\tTest Loss: 48.051 | Test Acc: 84.01%\n",
            "\n",
            "Epoch: 19\n",
            "\tTrain Loss: 151.832 | Train Acc: 86.86%\n",
            "\tTest Loss: 77.639 | Test Acc: 76.36%\n",
            "\n",
            "Epoch: 20\n",
            "\tTrain Loss: 147.963 | Train Acc: 87.03%\n",
            "\tTest Loss: 63.650 | Test Acc: 79.59%\n",
            "\n",
            "Epoch: 21\n",
            "\tTrain Loss: 146.788 | Train Acc: 87.13%\n",
            "\tTest Loss: 74.174 | Test Acc: 77.97%\n",
            "\n",
            "Epoch: 22\n",
            "\tTrain Loss: 145.628 | Train Acc: 87.11%\n",
            "\tTest Loss: 55.737 | Test Acc: 81.85%\n",
            "\n",
            "Epoch: 23\n",
            "\tTrain Loss: 145.339 | Train Acc: 87.30%\n",
            "\tTest Loss: 48.341 | Test Acc: 83.91%\n",
            "\n",
            "Epoch: 24\n",
            "\tTrain Loss: 140.442 | Train Acc: 87.63%\n",
            "\tTest Loss: 54.049 | Test Acc: 83.44%\n",
            "\n",
            "Epoch: 25\n",
            "\tTrain Loss: 144.474 | Train Acc: 87.40%\n",
            "\tTest Loss: 52.328 | Test Acc: 82.53%\n",
            "\n",
            "Epoch: 26\n",
            "\tTrain Loss: 140.166 | Train Acc: 87.63%\n",
            "\tTest Loss: 46.884 | Test Acc: 84.22%\n",
            "\n",
            "Epoch: 27\n",
            "\tTrain Loss: 139.632 | Train Acc: 87.79%\n",
            "\tTest Loss: 64.272 | Test Acc: 80.59%\n",
            "\n",
            "Epoch: 28\n",
            "\tTrain Loss: 137.536 | Train Acc: 87.97%\n",
            "\tTest Loss: 50.387 | Test Acc: 83.51%\n",
            "\n",
            "Epoch: 29\n",
            "\tTrain Loss: 139.353 | Train Acc: 87.77%\n",
            "\tTest Loss: 49.717 | Test Acc: 83.25%\n",
            "\n",
            "Epoch: 30\n",
            "\tTrain Loss: 134.659 | Train Acc: 88.22%\n",
            "\tTest Loss: 61.171 | Test Acc: 80.94%\n",
            "\n",
            "Epoch: 31\n",
            "\tTrain Loss: 134.587 | Train Acc: 88.15%\n",
            "\tTest Loss: 47.576 | Test Acc: 84.20%\n",
            "\n",
            "Epoch: 32\n",
            "\tTrain Loss: 135.515 | Train Acc: 88.15%\n",
            "\tTest Loss: 50.685 | Test Acc: 83.60%\n",
            "\n",
            "Epoch: 33\n",
            "\tTrain Loss: 133.622 | Train Acc: 88.38%\n",
            "\tTest Loss: 45.090 | Test Acc: 85.26%\n",
            "\n",
            "Epoch: 34\n",
            "\tTrain Loss: 132.613 | Train Acc: 88.27%\n",
            "\tTest Loss: 56.580 | Test Acc: 82.19%\n",
            "\n",
            "Epoch: 35\n",
            "\tTrain Loss: 134.376 | Train Acc: 88.29%\n",
            "\tTest Loss: 60.444 | Test Acc: 81.22%\n",
            "\n",
            "Epoch: 36\n",
            "\tTrain Loss: 131.341 | Train Acc: 88.59%\n",
            "\tTest Loss: 51.994 | Test Acc: 83.65%\n",
            "\n",
            "Epoch: 37\n",
            "\tTrain Loss: 131.888 | Train Acc: 88.53%\n",
            "\tTest Loss: 53.390 | Test Acc: 82.57%\n",
            "\n",
            "Epoch: 38\n",
            "\tTrain Loss: 131.263 | Train Acc: 88.50%\n",
            "\tTest Loss: 50.266 | Test Acc: 83.85%\n",
            "\n",
            "Epoch: 39\n",
            "\tTrain Loss: 130.685 | Train Acc: 88.55%\n",
            "\tTest Loss: 51.465 | Test Acc: 83.21%\n",
            "\n",
            "Epoch: 40\n",
            "\tTrain Loss: 128.466 | Train Acc: 88.77%\n",
            "\tTest Loss: 45.713 | Test Acc: 85.51%\n",
            "\n",
            "Epoch: 41\n",
            "\tTrain Loss: 129.841 | Train Acc: 88.65%\n",
            "\tTest Loss: 55.736 | Test Acc: 82.37%\n",
            "\n",
            "Epoch: 42\n",
            "\tTrain Loss: 126.510 | Train Acc: 89.04%\n",
            "\tTest Loss: 49.223 | Test Acc: 84.49%\n",
            "\n",
            "Epoch: 43\n",
            "\tTrain Loss: 127.509 | Train Acc: 88.82%\n",
            "\tTest Loss: 50.098 | Test Acc: 84.14%\n",
            "\n",
            "Epoch: 44\n",
            "\tTrain Loss: 126.244 | Train Acc: 88.99%\n",
            "\tTest Loss: 43.119 | Test Acc: 86.06%\n",
            "\n",
            "Epoch: 45\n",
            "\tTrain Loss: 124.114 | Train Acc: 88.97%\n",
            "\tTest Loss: 46.683 | Test Acc: 85.12%\n",
            "\n",
            "Epoch: 46\n",
            "\tTrain Loss: 122.718 | Train Acc: 89.08%\n",
            "\tTest Loss: 42.437 | Test Acc: 86.46%\n",
            "\n",
            "Epoch: 47\n",
            "\tTrain Loss: 122.518 | Train Acc: 89.35%\n",
            "\tTest Loss: 46.464 | Test Acc: 84.94%\n",
            "\n",
            "Epoch: 48\n",
            "\tTrain Loss: 122.786 | Train Acc: 89.21%\n",
            "\tTest Loss: 58.013 | Test Acc: 81.10%\n",
            "\n",
            "Epoch: 49\n",
            "\tTrain Loss: 122.320 | Train Acc: 89.38%\n",
            "\tTest Loss: 63.390 | Test Acc: 79.57%\n",
            "num_blocks=[1, 1, 2, 1]\n",
            "Model has too many parameters (6083914), will skip\n",
            "num_blocks=[1, 2, 0, 0]\n",
            "Will train model with 771914  parameters\n",
            "\n",
            "Epoch: 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/torchinfo/torchinfo.py:477: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  action_fn=lambda data: sys.getsizeof(data.storage()),\n",
            "/usr/local/lib/python3.9/dist-packages/torch/storage.py:665: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  return super().__sizeof__() + self.nbytes()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss: 655.609 | Train Acc: 37.22%\n",
            "\tTest Loss: 175.140 | Test Acc: 40.76%\n",
            "\n",
            "Epoch: 1\n",
            "\tTrain Loss: 508.087 | Train Acc: 53.07%\n",
            "\tTest Loss: 121.598 | Test Acc: 55.96%\n",
            "\n",
            "Epoch: 2\n",
            "\tTrain Loss: 429.662 | Train Acc: 60.68%\n",
            "\tTest Loss: 116.686 | Test Acc: 58.68%\n",
            "\n",
            "Epoch: 3\n",
            "\tTrain Loss: 376.711 | Train Acc: 65.91%\n",
            "\tTest Loss: 108.536 | Test Acc: 65.26%\n",
            "\n",
            "Epoch: 4\n",
            "\tTrain Loss: 340.198 | Train Acc: 69.69%\n",
            "\tTest Loss: 86.327 | Test Acc: 70.10%\n",
            "\n",
            "Epoch: 5\n",
            "\tTrain Loss: 317.246 | Train Acc: 71.92%\n",
            "\tTest Loss: 93.577 | Test Acc: 68.63%\n",
            "\n",
            "Epoch: 6\n",
            "\tTrain Loss: 298.276 | Train Acc: 73.58%\n",
            "\tTest Loss: 134.400 | Test Acc: 56.46%\n",
            "\n",
            "Epoch: 7\n",
            "\tTrain Loss: 285.698 | Train Acc: 74.74%\n",
            "\tTest Loss: 91.658 | Test Acc: 70.72%\n",
            "\n",
            "Epoch: 8\n",
            "\tTrain Loss: 276.334 | Train Acc: 75.64%\n",
            "\tTest Loss: 90.081 | Test Acc: 71.63%\n",
            "\n",
            "Epoch: 9\n",
            "\tTrain Loss: 269.509 | Train Acc: 76.14%\n",
            "\tTest Loss: 71.376 | Test Acc: 75.62%\n",
            "\n",
            "Epoch: 10\n",
            "\tTrain Loss: 262.483 | Train Acc: 76.99%\n",
            "\tTest Loss: 84.218 | Test Acc: 73.01%\n",
            "\n",
            "Epoch: 11\n",
            "\tTrain Loss: 255.249 | Train Acc: 77.61%\n",
            "\tTest Loss: 78.693 | Test Acc: 73.18%\n",
            "\n",
            "Epoch: 12\n",
            "\tTrain Loss: 251.603 | Train Acc: 77.89%\n",
            "\tTest Loss: 76.173 | Test Acc: 75.03%\n",
            "\n",
            "Epoch: 13\n",
            "\tTrain Loss: 248.434 | Train Acc: 78.13%\n",
            "\tTest Loss: 74.386 | Test Acc: 74.79%\n",
            "\n",
            "Epoch: 14\n",
            "\tTrain Loss: 242.598 | Train Acc: 78.67%\n",
            "\tTest Loss: 77.291 | Test Acc: 72.71%\n",
            "\n",
            "Epoch: 15\n",
            "\tTrain Loss: 240.217 | Train Acc: 79.02%\n",
            "\tTest Loss: 73.537 | Test Acc: 74.97%\n",
            "\n",
            "Epoch: 16\n",
            "\tTrain Loss: 239.570 | Train Acc: 78.90%\n",
            "\tTest Loss: 88.970 | Test Acc: 71.74%\n",
            "\n",
            "Epoch: 17\n",
            "\tTrain Loss: 233.516 | Train Acc: 79.50%\n",
            "\tTest Loss: 78.210 | Test Acc: 74.76%\n",
            "\n",
            "Epoch: 18\n",
            "\tTrain Loss: 231.681 | Train Acc: 79.50%\n",
            "\tTest Loss: 76.883 | Test Acc: 74.01%\n",
            "\n",
            "Epoch: 19\n",
            "\tTrain Loss: 229.041 | Train Acc: 79.85%\n",
            "\tTest Loss: 66.892 | Test Acc: 76.89%\n",
            "\n",
            "Epoch: 20\n",
            "\tTrain Loss: 228.035 | Train Acc: 80.03%\n",
            "\tTest Loss: 114.855 | Test Acc: 68.50%\n",
            "\n",
            "Epoch: 21\n",
            "\tTrain Loss: 227.621 | Train Acc: 80.17%\n",
            "\tTest Loss: 80.313 | Test Acc: 74.71%\n",
            "\n",
            "Epoch: 22\n",
            "\tTrain Loss: 226.127 | Train Acc: 80.20%\n",
            "\tTest Loss: 62.594 | Test Acc: 78.94%\n",
            "\n",
            "Epoch: 23\n",
            "\tTrain Loss: 223.734 | Train Acc: 80.59%\n",
            "\tTest Loss: 74.581 | Test Acc: 75.45%\n",
            "\n",
            "Epoch: 24\n",
            "\tTrain Loss: 220.233 | Train Acc: 80.82%\n",
            "\tTest Loss: 85.789 | Test Acc: 71.68%\n",
            "\n",
            "Epoch: 25\n",
            "\tTrain Loss: 218.670 | Train Acc: 80.89%\n",
            "\tTest Loss: 75.081 | Test Acc: 75.99%\n",
            "\n",
            "Epoch: 26\n",
            "\tTrain Loss: 217.928 | Train Acc: 80.76%\n",
            "\tTest Loss: 94.825 | Test Acc: 71.49%\n",
            "\n",
            "Epoch: 27\n",
            "\tTrain Loss: 215.579 | Train Acc: 81.18%\n",
            "\tTest Loss: 111.117 | Test Acc: 64.67%\n",
            "\n",
            "Epoch: 28\n",
            "\tTrain Loss: 214.894 | Train Acc: 81.18%\n",
            "\tTest Loss: 63.841 | Test Acc: 78.73%\n",
            "\n",
            "Epoch: 29\n",
            "\tTrain Loss: 214.170 | Train Acc: 81.30%\n",
            "\tTest Loss: 73.710 | Test Acc: 75.28%\n",
            "\n",
            "Epoch: 30\n",
            "\tTrain Loss: 214.693 | Train Acc: 81.35%\n",
            "\tTest Loss: 97.473 | Test Acc: 69.50%\n",
            "\n",
            "Epoch: 31\n",
            "\tTrain Loss: 211.680 | Train Acc: 81.49%\n",
            "\tTest Loss: 71.128 | Test Acc: 76.42%\n",
            "\n",
            "Epoch: 32\n",
            "\tTrain Loss: 210.983 | Train Acc: 81.53%\n",
            "\tTest Loss: 73.337 | Test Acc: 76.66%\n",
            "\n",
            "Epoch: 33\n",
            "\tTrain Loss: 212.340 | Train Acc: 81.54%\n",
            "\tTest Loss: 63.647 | Test Acc: 78.29%\n",
            "\n",
            "Epoch: 34\n",
            "\tTrain Loss: 209.730 | Train Acc: 81.60%\n",
            "\tTest Loss: 83.447 | Test Acc: 72.43%\n",
            "\n",
            "Epoch: 35\n",
            "\tTrain Loss: 209.722 | Train Acc: 81.69%\n",
            "\tTest Loss: 69.390 | Test Acc: 76.15%\n",
            "\n",
            "Epoch: 36\n",
            "\tTrain Loss: 210.007 | Train Acc: 81.77%\n",
            "\tTest Loss: 65.945 | Test Acc: 77.17%\n",
            "\n",
            "Epoch: 37\n",
            "\tTrain Loss: 206.885 | Train Acc: 82.03%\n",
            "\tTest Loss: 64.427 | Test Acc: 78.31%\n",
            "\n",
            "Epoch: 38\n",
            "\tTrain Loss: 205.005 | Train Acc: 82.20%\n",
            "\tTest Loss: 78.759 | Test Acc: 74.45%\n",
            "\n",
            "Epoch: 39\n",
            "\tTrain Loss: 205.918 | Train Acc: 81.84%\n",
            "\tTest Loss: 67.254 | Test Acc: 77.59%\n",
            "\n",
            "Epoch: 40\n",
            "\tTrain Loss: 200.839 | Train Acc: 82.47%\n",
            "\tTest Loss: 72.533 | Test Acc: 76.52%\n",
            "\n",
            "Epoch: 41\n",
            "\tTrain Loss: 205.610 | Train Acc: 82.04%\n",
            "\tTest Loss: 59.107 | Test Acc: 80.21%\n",
            "\n",
            "Epoch: 42\n",
            "\tTrain Loss: 203.607 | Train Acc: 82.39%\n",
            "\tTest Loss: 76.638 | Test Acc: 76.07%\n",
            "\n",
            "Epoch: 43\n",
            "\tTrain Loss: 200.576 | Train Acc: 82.49%\n",
            "\tTest Loss: 69.567 | Test Acc: 75.97%\n",
            "\n",
            "Epoch: 44\n",
            "\tTrain Loss: 202.697 | Train Acc: 82.20%\n",
            "\tTest Loss: 72.231 | Test Acc: 76.71%\n",
            "\n",
            "Epoch: 45\n",
            "\tTrain Loss: 202.764 | Train Acc: 82.12%\n",
            "\tTest Loss: 82.705 | Test Acc: 73.65%\n",
            "\n",
            "Epoch: 46\n",
            "\tTrain Loss: 200.464 | Train Acc: 82.52%\n",
            "\tTest Loss: 63.320 | Test Acc: 78.10%\n",
            "\n",
            "Epoch: 47\n",
            "\tTrain Loss: 198.592 | Train Acc: 82.72%\n",
            "\tTest Loss: 61.871 | Test Acc: 79.01%\n",
            "\n",
            "Epoch: 48\n",
            "\tTrain Loss: 200.903 | Train Acc: 82.62%\n",
            "\tTest Loss: 78.578 | Test Acc: 74.21%\n",
            "\n",
            "Epoch: 49\n",
            "\tTrain Loss: 198.245 | Train Acc: 82.58%\n",
            "\tTest Loss: 66.926 | Test Acc: 76.93%\n",
            "num_blocks=[1, 2, 0, 1]\n",
            "Will train model with 4312906  parameters\n",
            "\n",
            "Epoch: 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/torchinfo/torchinfo.py:477: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  action_fn=lambda data: sys.getsizeof(data.storage()),\n",
            "/usr/local/lib/python3.9/dist-packages/torch/storage.py:665: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  return super().__sizeof__() + self.nbytes()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss: 577.722 | Train Acc: 45.76%\n",
            "\tTest Loss: 127.187 | Test Acc: 54.91%\n",
            "\n",
            "Epoch: 1\n",
            "\tTrain Loss: 397.430 | Train Acc: 63.70%\n",
            "\tTest Loss: 100.386 | Test Acc: 65.20%\n",
            "\n",
            "Epoch: 2\n",
            "\tTrain Loss: 320.091 | Train Acc: 71.15%\n",
            "\tTest Loss: 86.848 | Test Acc: 70.26%\n",
            "\n",
            "Epoch: 3\n",
            "\tTrain Loss: 276.552 | Train Acc: 75.24%\n",
            "\tTest Loss: 72.366 | Test Acc: 74.88%\n",
            "\n",
            "Epoch: 4\n",
            "\tTrain Loss: 250.278 | Train Acc: 77.76%\n",
            "\tTest Loss: 75.800 | Test Acc: 74.22%\n",
            "\n",
            "Epoch: 5\n",
            "\tTrain Loss: 234.369 | Train Acc: 79.42%\n",
            "\tTest Loss: 82.241 | Test Acc: 72.37%\n",
            "\n",
            "Epoch: 6\n",
            "\tTrain Loss: 222.160 | Train Acc: 80.33%\n",
            "\tTest Loss: 81.227 | Test Acc: 73.75%\n",
            "\n",
            "Epoch: 7\n",
            "\tTrain Loss: 216.592 | Train Acc: 80.97%\n",
            "\tTest Loss: 74.539 | Test Acc: 75.21%\n",
            "\n",
            "Epoch: 8\n",
            "\tTrain Loss: 206.494 | Train Acc: 81.79%\n",
            "\tTest Loss: 98.876 | Test Acc: 69.93%\n",
            "\n",
            "Epoch: 9\n",
            "\tTrain Loss: 203.770 | Train Acc: 82.04%\n",
            "\tTest Loss: 91.440 | Test Acc: 73.46%\n",
            "\n",
            "Epoch: 10\n",
            "\tTrain Loss: 197.475 | Train Acc: 82.71%\n",
            "\tTest Loss: 64.517 | Test Acc: 78.44%\n",
            "\n",
            "Epoch: 11\n",
            "\tTrain Loss: 194.553 | Train Acc: 82.93%\n",
            "\tTest Loss: 61.380 | Test Acc: 78.86%\n",
            "\n",
            "Epoch: 12\n",
            "\tTrain Loss: 189.577 | Train Acc: 83.29%\n",
            "\tTest Loss: 83.547 | Test Acc: 74.23%\n",
            "\n",
            "Epoch: 13\n",
            "\tTrain Loss: 186.930 | Train Acc: 83.73%\n",
            "\tTest Loss: 79.800 | Test Acc: 74.47%\n",
            "\n",
            "Epoch: 14\n",
            "\tTrain Loss: 183.989 | Train Acc: 84.01%\n",
            "\tTest Loss: 71.725 | Test Acc: 77.37%\n",
            "\n",
            "Epoch: 15\n",
            "\tTrain Loss: 181.705 | Train Acc: 84.19%\n",
            "\tTest Loss: 64.865 | Test Acc: 79.35%\n",
            "\n",
            "Epoch: 16\n",
            "\tTrain Loss: 177.395 | Train Acc: 84.45%\n",
            "\tTest Loss: 75.550 | Test Acc: 76.31%\n",
            "\n",
            "Epoch: 17\n",
            "\tTrain Loss: 177.778 | Train Acc: 84.31%\n",
            "\tTest Loss: 84.769 | Test Acc: 75.44%\n",
            "\n",
            "Epoch: 18\n",
            "\tTrain Loss: 176.424 | Train Acc: 84.51%\n",
            "\tTest Loss: 56.979 | Test Acc: 80.49%\n",
            "\n",
            "Epoch: 19\n",
            "\tTrain Loss: 175.854 | Train Acc: 84.64%\n",
            "\tTest Loss: 48.065 | Test Acc: 83.42%\n",
            "\n",
            "Epoch: 20\n",
            "\tTrain Loss: 171.555 | Train Acc: 85.07%\n",
            "\tTest Loss: 57.816 | Test Acc: 80.48%\n",
            "\n",
            "Epoch: 21\n",
            "\tTrain Loss: 170.375 | Train Acc: 85.03%\n",
            "\tTest Loss: 68.030 | Test Acc: 78.84%\n",
            "\n",
            "Epoch: 22\n",
            "\tTrain Loss: 169.245 | Train Acc: 85.23%\n",
            "\tTest Loss: 77.428 | Test Acc: 75.15%\n",
            "\n",
            "Epoch: 23\n",
            "\tTrain Loss: 168.225 | Train Acc: 85.47%\n",
            "\tTest Loss: 65.556 | Test Acc: 78.69%\n",
            "\n",
            "Epoch: 24\n",
            "\tTrain Loss: 165.760 | Train Acc: 85.46%\n",
            "\tTest Loss: 72.324 | Test Acc: 76.32%\n",
            "\n",
            "Epoch: 25\n",
            "\tTrain Loss: 163.839 | Train Acc: 85.64%\n",
            "\tTest Loss: 63.192 | Test Acc: 79.19%\n",
            "\n",
            "Epoch: 26\n",
            "\tTrain Loss: 164.333 | Train Acc: 85.60%\n",
            "\tTest Loss: 76.742 | Test Acc: 77.25%\n",
            "\n",
            "Epoch: 27\n",
            "\tTrain Loss: 161.196 | Train Acc: 85.68%\n",
            "\tTest Loss: 67.287 | Test Acc: 79.72%\n",
            "\n",
            "Epoch: 28\n",
            "\tTrain Loss: 161.124 | Train Acc: 85.94%\n",
            "\tTest Loss: 74.191 | Test Acc: 75.33%\n",
            "\n",
            "Epoch: 29\n",
            "\tTrain Loss: 163.323 | Train Acc: 85.80%\n",
            "\tTest Loss: 47.247 | Test Acc: 83.45%\n",
            "\n",
            "Epoch: 30\n",
            "\tTrain Loss: 159.724 | Train Acc: 86.15%\n",
            "\tTest Loss: 56.991 | Test Acc: 80.51%\n",
            "\n",
            "Epoch: 31\n",
            "\tTrain Loss: 159.269 | Train Acc: 85.88%\n",
            "\tTest Loss: 61.531 | Test Acc: 80.11%\n",
            "\n",
            "Epoch: 32\n",
            "\tTrain Loss: 156.882 | Train Acc: 86.36%\n",
            "\tTest Loss: 61.297 | Test Acc: 79.89%\n",
            "\n",
            "Epoch: 33\n",
            "\tTrain Loss: 157.067 | Train Acc: 86.26%\n",
            "\tTest Loss: 62.105 | Test Acc: 79.27%\n",
            "\n",
            "Epoch: 34\n",
            "\tTrain Loss: 158.145 | Train Acc: 86.17%\n",
            "\tTest Loss: 70.275 | Test Acc: 77.95%\n",
            "\n",
            "Epoch: 35\n",
            "\tTrain Loss: 154.344 | Train Acc: 86.52%\n",
            "\tTest Loss: 54.833 | Test Acc: 82.36%\n",
            "\n",
            "Epoch: 36\n",
            "\tTrain Loss: 155.862 | Train Acc: 86.47%\n",
            "\tTest Loss: 58.932 | Test Acc: 80.85%\n",
            "\n",
            "Epoch: 37\n",
            "\tTrain Loss: 156.275 | Train Acc: 86.28%\n",
            "\tTest Loss: 65.237 | Test Acc: 78.61%\n",
            "\n",
            "Epoch: 38\n",
            "\tTrain Loss: 154.488 | Train Acc: 86.60%\n",
            "\tTest Loss: 59.415 | Test Acc: 80.79%\n",
            "\n",
            "Epoch: 39\n",
            "\tTrain Loss: 151.875 | Train Acc: 86.70%\n",
            "\tTest Loss: 51.638 | Test Acc: 82.75%\n",
            "\n",
            "Epoch: 40\n",
            "\tTrain Loss: 153.072 | Train Acc: 86.55%\n",
            "\tTest Loss: 74.107 | Test Acc: 77.87%\n",
            "\n",
            "Epoch: 41\n",
            "\tTrain Loss: 150.770 | Train Acc: 86.88%\n",
            "\tTest Loss: 56.718 | Test Acc: 82.14%\n",
            "\n",
            "Epoch: 42\n",
            "\tTrain Loss: 152.239 | Train Acc: 86.59%\n",
            "\tTest Loss: 59.866 | Test Acc: 80.36%\n",
            "\n",
            "Epoch: 43\n",
            "\tTrain Loss: 149.726 | Train Acc: 86.87%\n",
            "\tTest Loss: 58.312 | Test Acc: 80.37%\n",
            "\n",
            "Epoch: 44\n",
            "\tTrain Loss: 148.837 | Train Acc: 87.03%\n",
            "\tTest Loss: 65.028 | Test Acc: 79.23%\n",
            "\n",
            "Epoch: 45\n",
            "\tTrain Loss: 146.681 | Train Acc: 87.12%\n",
            "\tTest Loss: 69.977 | Test Acc: 78.98%\n",
            "\n",
            "Epoch: 46\n",
            "\tTrain Loss: 147.662 | Train Acc: 87.08%\n",
            "\tTest Loss: 52.798 | Test Acc: 82.66%\n",
            "\n",
            "Epoch: 47\n",
            "\tTrain Loss: 146.418 | Train Acc: 87.34%\n",
            "\tTest Loss: 56.187 | Test Acc: 81.74%\n",
            "\n",
            "Epoch: 48\n",
            "\tTrain Loss: 144.947 | Train Acc: 87.34%\n",
            "\tTest Loss: 56.339 | Test Acc: 81.33%\n",
            "\n",
            "Epoch: 49\n",
            "\tTrain Loss: 146.770 | Train Acc: 87.14%\n",
            "\tTest Loss: 54.524 | Test Acc: 81.89%\n",
            "num_blocks=[1, 2, 1, 0]\n",
            "Will train model with 1657674  parameters\n",
            "\n",
            "Epoch: 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/torchinfo/torchinfo.py:477: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  action_fn=lambda data: sys.getsizeof(data.storage()),\n",
            "/usr/local/lib/python3.9/dist-packages/torch/storage.py:665: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  return super().__sizeof__() + self.nbytes()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss: 611.365 | Train Acc: 41.97%\n",
            "\tTest Loss: 126.812 | Test Acc: 53.65%\n",
            "\n",
            "Epoch: 1\n",
            "\tTrain Loss: 425.657 | Train Acc: 60.87%\n",
            "\tTest Loss: 92.244 | Test Acc: 67.43%\n",
            "\n",
            "Epoch: 2\n",
            "\tTrain Loss: 336.774 | Train Acc: 69.45%\n",
            "\tTest Loss: 81.514 | Test Acc: 71.56%\n",
            "\n",
            "Epoch: 3\n",
            "\tTrain Loss: 287.054 | Train Acc: 74.38%\n",
            "\tTest Loss: 84.463 | Test Acc: 70.63%\n",
            "\n",
            "Epoch: 4\n",
            "\tTrain Loss: 256.831 | Train Acc: 77.25%\n",
            "\tTest Loss: 69.697 | Test Acc: 76.46%\n",
            "\n",
            "Epoch: 5\n",
            "\tTrain Loss: 238.896 | Train Acc: 78.91%\n",
            "\tTest Loss: 76.464 | Test Acc: 73.32%\n",
            "\n",
            "Epoch: 6\n",
            "\tTrain Loss: 226.432 | Train Acc: 79.97%\n",
            "\tTest Loss: 99.403 | Test Acc: 67.57%\n",
            "\n",
            "Epoch: 7\n",
            "\tTrain Loss: 217.448 | Train Acc: 80.97%\n",
            "\tTest Loss: 75.696 | Test Acc: 75.68%\n",
            "\n",
            "Epoch: 8\n",
            "\tTrain Loss: 209.487 | Train Acc: 81.68%\n",
            "\tTest Loss: 58.509 | Test Acc: 80.18%\n",
            "\n",
            "Epoch: 9\n",
            "\tTrain Loss: 201.290 | Train Acc: 82.18%\n",
            "\tTest Loss: 81.479 | Test Acc: 75.50%\n",
            "\n",
            "Epoch: 10\n",
            "\tTrain Loss: 196.568 | Train Acc: 82.83%\n",
            "\tTest Loss: 91.967 | Test Acc: 72.94%\n",
            "\n",
            "Epoch: 11\n",
            "\tTrain Loss: 189.339 | Train Acc: 83.42%\n",
            "\tTest Loss: 64.636 | Test Acc: 78.74%\n",
            "\n",
            "Epoch: 12\n",
            "\tTrain Loss: 187.379 | Train Acc: 83.51%\n",
            "\tTest Loss: 57.532 | Test Acc: 81.12%\n",
            "\n",
            "Epoch: 13\n",
            "\tTrain Loss: 182.033 | Train Acc: 84.01%\n",
            "\tTest Loss: 68.989 | Test Acc: 77.60%\n",
            "\n",
            "Epoch: 14\n",
            "\tTrain Loss: 177.095 | Train Acc: 84.33%\n",
            "\tTest Loss: 68.562 | Test Acc: 77.46%\n",
            "\n",
            "Epoch: 15\n",
            "\tTrain Loss: 176.110 | Train Acc: 84.50%\n",
            "\tTest Loss: 49.544 | Test Acc: 83.46%\n",
            "\n",
            "Epoch: 16\n",
            "\tTrain Loss: 172.230 | Train Acc: 84.98%\n",
            "\tTest Loss: 68.637 | Test Acc: 79.08%\n",
            "\n",
            "Epoch: 17\n",
            "\tTrain Loss: 173.976 | Train Acc: 84.75%\n",
            "\tTest Loss: 59.468 | Test Acc: 79.81%\n",
            "\n",
            "Epoch: 18\n",
            "\tTrain Loss: 168.282 | Train Acc: 85.46%\n",
            "\tTest Loss: 65.038 | Test Acc: 79.01%\n",
            "\n",
            "Epoch: 19\n",
            "\tTrain Loss: 165.817 | Train Acc: 85.44%\n",
            "\tTest Loss: 67.893 | Test Acc: 78.28%\n",
            "\n",
            "Epoch: 20\n",
            "\tTrain Loss: 165.625 | Train Acc: 85.36%\n",
            "\tTest Loss: 72.736 | Test Acc: 76.01%\n",
            "\n",
            "Epoch: 21\n",
            "\tTrain Loss: 161.502 | Train Acc: 85.84%\n",
            "\tTest Loss: 53.406 | Test Acc: 82.35%\n",
            "\n",
            "Epoch: 22\n",
            "\tTrain Loss: 160.857 | Train Acc: 85.91%\n",
            "\tTest Loss: 77.595 | Test Acc: 76.65%\n",
            "\n",
            "Epoch: 23\n",
            "\tTrain Loss: 158.118 | Train Acc: 86.27%\n",
            "\tTest Loss: 91.234 | Test Acc: 74.18%\n",
            "\n",
            "Epoch: 24\n",
            "\tTrain Loss: 159.640 | Train Acc: 86.00%\n",
            "\tTest Loss: 53.183 | Test Acc: 82.67%\n",
            "\n",
            "Epoch: 25\n",
            "\tTrain Loss: 154.393 | Train Acc: 86.47%\n",
            "\tTest Loss: 53.183 | Test Acc: 82.10%\n",
            "\n",
            "Epoch: 26\n",
            "\tTrain Loss: 155.111 | Train Acc: 86.45%\n",
            "\tTest Loss: 68.353 | Test Acc: 78.42%\n",
            "\n",
            "Epoch: 27\n",
            "\tTrain Loss: 151.608 | Train Acc: 86.77%\n",
            "\tTest Loss: 69.540 | Test Acc: 77.86%\n",
            "\n",
            "Epoch: 28\n",
            "\tTrain Loss: 155.117 | Train Acc: 86.47%\n",
            "\tTest Loss: 56.338 | Test Acc: 81.93%\n",
            "\n",
            "Epoch: 29\n",
            "\tTrain Loss: 152.580 | Train Acc: 86.64%\n",
            "\tTest Loss: 58.614 | Test Acc: 80.95%\n",
            "\n",
            "Epoch: 30\n",
            "\tTrain Loss: 154.094 | Train Acc: 86.50%\n",
            "\tTest Loss: 50.584 | Test Acc: 83.19%\n",
            "\n",
            "Epoch: 31\n",
            "\tTrain Loss: 149.736 | Train Acc: 86.94%\n",
            "\tTest Loss: 64.695 | Test Acc: 79.22%\n",
            "\n",
            "Epoch: 32\n",
            "\tTrain Loss: 150.030 | Train Acc: 86.84%\n",
            "\tTest Loss: 83.948 | Test Acc: 72.95%\n",
            "\n",
            "Epoch: 33\n",
            "\tTrain Loss: 148.837 | Train Acc: 86.94%\n",
            "\tTest Loss: 75.067 | Test Acc: 77.26%\n",
            "\n",
            "Epoch: 34\n",
            "\tTrain Loss: 149.162 | Train Acc: 86.89%\n",
            "\tTest Loss: 61.162 | Test Acc: 80.23%\n",
            "\n",
            "Epoch: 35\n",
            "\tTrain Loss: 146.198 | Train Acc: 87.03%\n",
            "\tTest Loss: 63.249 | Test Acc: 79.30%\n",
            "\n",
            "Epoch: 36\n",
            "\tTrain Loss: 148.415 | Train Acc: 86.99%\n",
            "\tTest Loss: 53.243 | Test Acc: 82.78%\n",
            "\n",
            "Epoch: 37\n",
            "\tTrain Loss: 145.180 | Train Acc: 87.26%\n",
            "\tTest Loss: 48.709 | Test Acc: 84.09%\n",
            "\n",
            "Epoch: 38\n",
            "\tTrain Loss: 143.847 | Train Acc: 87.25%\n",
            "\tTest Loss: 58.497 | Test Acc: 81.10%\n",
            "\n",
            "Epoch: 39\n",
            "\tTrain Loss: 144.543 | Train Acc: 87.32%\n",
            "\tTest Loss: 53.569 | Test Acc: 83.30%\n",
            "\n",
            "Epoch: 40\n",
            "\tTrain Loss: 142.323 | Train Acc: 87.50%\n",
            "\tTest Loss: 56.768 | Test Acc: 82.03%\n",
            "\n",
            "Epoch: 41\n",
            "\tTrain Loss: 144.599 | Train Acc: 87.33%\n",
            "\tTest Loss: 82.047 | Test Acc: 75.51%\n",
            "\n",
            "Epoch: 42\n",
            "\tTrain Loss: 140.108 | Train Acc: 87.92%\n",
            "\tTest Loss: 50.445 | Test Acc: 83.81%\n",
            "\n",
            "Epoch: 43\n",
            "\tTrain Loss: 140.068 | Train Acc: 87.78%\n",
            "\tTest Loss: 50.592 | Test Acc: 84.06%\n",
            "\n",
            "Epoch: 44\n",
            "\tTrain Loss: 138.452 | Train Acc: 87.96%\n",
            "\tTest Loss: 67.636 | Test Acc: 79.78%\n",
            "\n",
            "Epoch: 45\n",
            "\tTrain Loss: 139.656 | Train Acc: 87.99%\n",
            "\tTest Loss: 68.348 | Test Acc: 78.94%\n",
            "\n",
            "Epoch: 46\n",
            "\tTrain Loss: 138.891 | Train Acc: 87.79%\n",
            "\tTest Loss: 67.627 | Test Acc: 80.21%\n",
            "\n",
            "Epoch: 47\n",
            "\tTrain Loss: 140.182 | Train Acc: 87.67%\n",
            "\tTest Loss: 55.169 | Test Acc: 82.13%\n",
            "\n",
            "Epoch: 48\n",
            "\tTrain Loss: 135.173 | Train Acc: 88.19%\n",
            "\tTest Loss: 63.050 | Test Acc: 80.81%\n",
            "\n",
            "Epoch: 49\n",
            "\tTrain Loss: 137.526 | Train Acc: 87.79%\n",
            "\tTest Loss: 57.090 | Test Acc: 81.73%\n",
            "num_blocks=[1, 2, 1, 1]\n",
            "Model has too many parameters (5198666), will skip\n",
            "num_blocks=[1, 2, 2, 0]\n",
            "Will train model with 2838346  parameters\n",
            "\n",
            "Epoch: 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/torchinfo/torchinfo.py:477: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  action_fn=lambda data: sys.getsizeof(data.storage()),\n",
            "/usr/local/lib/python3.9/dist-packages/torch/storage.py:665: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  return super().__sizeof__() + self.nbytes()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss: 627.824 | Train Acc: 40.42%\n",
            "\tTest Loss: 140.546 | Test Acc: 50.44%\n",
            "\n",
            "Epoch: 1\n",
            "\tTrain Loss: 434.452 | Train Acc: 60.09%\n",
            "\tTest Loss: 99.475 | Test Acc: 65.34%\n",
            "\n",
            "Epoch: 2\n",
            "\tTrain Loss: 331.965 | Train Acc: 70.04%\n",
            "\tTest Loss: 94.371 | Test Acc: 68.65%\n",
            "\n",
            "Epoch: 3\n",
            "\tTrain Loss: 278.191 | Train Acc: 75.28%\n",
            "\tTest Loss: 71.742 | Test Acc: 75.51%\n",
            "\n",
            "Epoch: 4\n",
            "\tTrain Loss: 240.727 | Train Acc: 78.67%\n",
            "\tTest Loss: 77.284 | Test Acc: 74.06%\n",
            "\n",
            "Epoch: 5\n",
            "\tTrain Loss: 218.446 | Train Acc: 80.64%\n",
            "\tTest Loss: 73.670 | Test Acc: 76.38%\n",
            "\n",
            "Epoch: 6\n",
            "\tTrain Loss: 204.978 | Train Acc: 81.99%\n",
            "\tTest Loss: 60.500 | Test Acc: 80.13%\n",
            "\n",
            "Epoch: 7\n",
            "\tTrain Loss: 196.371 | Train Acc: 82.75%\n",
            "\tTest Loss: 61.038 | Test Acc: 79.93%\n",
            "\n",
            "Epoch: 8\n",
            "\tTrain Loss: 188.380 | Train Acc: 83.44%\n",
            "\tTest Loss: 77.699 | Test Acc: 75.15%\n",
            "\n",
            "Epoch: 9\n",
            "\tTrain Loss: 182.671 | Train Acc: 83.96%\n",
            "\tTest Loss: 53.142 | Test Acc: 82.51%\n",
            "\n",
            "Epoch: 10\n",
            "\tTrain Loss: 175.700 | Train Acc: 84.56%\n",
            "\tTest Loss: 84.388 | Test Acc: 74.81%\n",
            "\n",
            "Epoch: 11\n",
            "\tTrain Loss: 171.471 | Train Acc: 85.08%\n",
            "\tTest Loss: 63.016 | Test Acc: 79.23%\n",
            "\n",
            "Epoch: 12\n",
            "\tTrain Loss: 165.888 | Train Acc: 85.56%\n",
            "\tTest Loss: 117.004 | Test Acc: 69.23%\n",
            "\n",
            "Epoch: 13\n",
            "\tTrain Loss: 164.105 | Train Acc: 85.62%\n",
            "\tTest Loss: 58.112 | Test Acc: 81.37%\n",
            "\n",
            "Epoch: 14\n",
            "\tTrain Loss: 158.440 | Train Acc: 86.07%\n",
            "\tTest Loss: 90.232 | Test Acc: 74.75%\n",
            "\n",
            "Epoch: 15\n",
            "\tTrain Loss: 155.724 | Train Acc: 86.34%\n",
            "\tTest Loss: 67.099 | Test Acc: 78.82%\n",
            "\n",
            "Epoch: 16\n",
            "\tTrain Loss: 154.918 | Train Acc: 86.39%\n",
            "\tTest Loss: 53.323 | Test Acc: 81.96%\n",
            "\n",
            "Epoch: 17\n",
            "\tTrain Loss: 150.261 | Train Acc: 86.71%\n",
            "\tTest Loss: 50.337 | Test Acc: 84.06%\n",
            "\n",
            "Epoch: 18\n",
            "\tTrain Loss: 148.542 | Train Acc: 87.06%\n",
            "\tTest Loss: 68.765 | Test Acc: 78.91%\n",
            "\n",
            "Epoch: 19\n",
            "\tTrain Loss: 146.255 | Train Acc: 87.15%\n",
            "\tTest Loss: 53.005 | Test Acc: 82.47%\n",
            "\n",
            "Epoch: 20\n",
            "\tTrain Loss: 145.637 | Train Acc: 87.27%\n",
            "\tTest Loss: 69.103 | Test Acc: 79.13%\n",
            "\n",
            "Epoch: 21\n",
            "\tTrain Loss: 143.290 | Train Acc: 87.35%\n",
            "\tTest Loss: 54.822 | Test Acc: 82.73%\n",
            "\n",
            "Epoch: 22\n",
            "\tTrain Loss: 143.241 | Train Acc: 87.52%\n",
            "\tTest Loss: 67.652 | Test Acc: 78.67%\n",
            "\n",
            "Epoch: 23\n",
            "\tTrain Loss: 142.373 | Train Acc: 87.63%\n",
            "\tTest Loss: 57.793 | Test Acc: 81.90%\n",
            "\n",
            "Epoch: 24\n",
            "\tTrain Loss: 139.562 | Train Acc: 87.80%\n",
            "\tTest Loss: 59.312 | Test Acc: 80.96%\n",
            "\n",
            "Epoch: 25\n",
            "\tTrain Loss: 136.669 | Train Acc: 88.06%\n",
            "\tTest Loss: 75.910 | Test Acc: 76.30%\n",
            "\n",
            "Epoch: 26\n",
            "\tTrain Loss: 137.116 | Train Acc: 88.03%\n",
            "\tTest Loss: 64.651 | Test Acc: 78.86%\n",
            "\n",
            "Epoch: 27\n",
            "\tTrain Loss: 135.728 | Train Acc: 88.20%\n",
            "\tTest Loss: 50.157 | Test Acc: 83.80%\n",
            "\n",
            "Epoch: 28\n",
            "\tTrain Loss: 133.359 | Train Acc: 88.34%\n",
            "\tTest Loss: 64.159 | Test Acc: 80.25%\n",
            "\n",
            "Epoch: 29\n",
            "\tTrain Loss: 135.735 | Train Acc: 88.06%\n",
            "\tTest Loss: 72.279 | Test Acc: 78.57%\n",
            "\n",
            "Epoch: 30\n",
            "\tTrain Loss: 131.786 | Train Acc: 88.48%\n",
            "\tTest Loss: 68.859 | Test Acc: 79.53%\n",
            "\n",
            "Epoch: 31\n",
            "\tTrain Loss: 132.787 | Train Acc: 88.28%\n",
            "\tTest Loss: 52.364 | Test Acc: 83.06%\n",
            "\n",
            "Epoch: 32\n",
            "\tTrain Loss: 133.983 | Train Acc: 88.20%\n",
            "\tTest Loss: 44.911 | Test Acc: 84.83%\n",
            "\n",
            "Epoch: 33\n",
            "\tTrain Loss: 130.210 | Train Acc: 88.60%\n",
            "\tTest Loss: 54.661 | Test Acc: 81.87%\n",
            "\n",
            "Epoch: 34\n",
            "\tTrain Loss: 127.577 | Train Acc: 88.87%\n",
            "\tTest Loss: 44.980 | Test Acc: 85.36%\n",
            "\n",
            "Epoch: 35\n",
            "\tTrain Loss: 128.980 | Train Acc: 88.52%\n",
            "\tTest Loss: 56.445 | Test Acc: 82.54%\n",
            "\n",
            "Epoch: 36\n",
            "\tTrain Loss: 127.919 | Train Acc: 88.76%\n",
            "\tTest Loss: 52.651 | Test Acc: 82.68%\n",
            "\n",
            "Epoch: 37\n",
            "\tTrain Loss: 126.559 | Train Acc: 88.88%\n",
            "\tTest Loss: 46.976 | Test Acc: 84.48%\n",
            "\n",
            "Epoch: 38\n",
            "\tTrain Loss: 127.387 | Train Acc: 88.90%\n",
            "\tTest Loss: 63.030 | Test Acc: 81.66%\n",
            "\n",
            "Epoch: 39\n",
            "\tTrain Loss: 125.728 | Train Acc: 88.97%\n",
            "\tTest Loss: 59.921 | Test Acc: 81.42%\n",
            "\n",
            "Epoch: 40\n",
            "\tTrain Loss: 124.383 | Train Acc: 89.17%\n",
            "\tTest Loss: 47.444 | Test Acc: 84.60%\n",
            "\n",
            "Epoch: 41\n",
            "\tTrain Loss: 123.919 | Train Acc: 89.05%\n",
            "\tTest Loss: 56.492 | Test Acc: 82.27%\n",
            "\n",
            "Epoch: 42\n",
            "\tTrain Loss: 123.316 | Train Acc: 89.11%\n",
            "\tTest Loss: 44.110 | Test Acc: 84.79%\n",
            "\n",
            "Epoch: 43\n",
            "\tTrain Loss: 123.872 | Train Acc: 89.10%\n",
            "\tTest Loss: 53.884 | Test Acc: 82.96%\n",
            "\n",
            "Epoch: 44\n",
            "\tTrain Loss: 121.430 | Train Acc: 89.39%\n",
            "\tTest Loss: 53.364 | Test Acc: 83.71%\n",
            "\n",
            "Epoch: 45\n",
            "\tTrain Loss: 121.082 | Train Acc: 89.43%\n",
            "\tTest Loss: 47.240 | Test Acc: 84.83%\n",
            "\n",
            "Epoch: 46\n",
            "\tTrain Loss: 117.541 | Train Acc: 89.63%\n",
            "\tTest Loss: 51.315 | Test Acc: 83.12%\n",
            "\n",
            "Epoch: 47\n",
            "\tTrain Loss: 118.723 | Train Acc: 89.50%\n",
            "\tTest Loss: 61.004 | Test Acc: 81.46%\n",
            "\n",
            "Epoch: 48\n",
            "\tTrain Loss: 121.174 | Train Acc: 89.37%\n",
            "\tTest Loss: 65.522 | Test Acc: 79.51%\n",
            "\n",
            "Epoch: 49\n",
            "\tTrain Loss: 117.952 | Train Acc: 89.65%\n",
            "\tTest Loss: 39.739 | Test Acc: 87.18%\n",
            "num_blocks=[1, 2, 2, 1]\n",
            "Model has too many parameters (6379338), will skip\n",
            "num_blocks=[1, 3, 0, 0]\n",
            "Will train model with 1067338  parameters\n",
            "\n",
            "Epoch: 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/torchinfo/torchinfo.py:477: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  action_fn=lambda data: sys.getsizeof(data.storage()),\n",
            "/usr/local/lib/python3.9/dist-packages/torch/storage.py:665: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  return super().__sizeof__() + self.nbytes()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss: 654.464 | Train Acc: 37.18%\n",
            "\tTest Loss: 152.042 | Test Acc: 46.10%\n",
            "\n",
            "Epoch: 1\n",
            "\tTrain Loss: 476.785 | Train Acc: 56.10%\n",
            "\tTest Loss: 118.456 | Test Acc: 57.91%\n",
            "\n",
            "Epoch: 2\n",
            "\tTrain Loss: 381.609 | Train Acc: 65.53%\n",
            "\tTest Loss: 90.269 | Test Acc: 68.59%\n",
            "\n",
            "Epoch: 3\n",
            "\tTrain Loss: 319.248 | Train Acc: 71.51%\n",
            "\tTest Loss: 109.991 | Test Acc: 64.01%\n",
            "\n",
            "Epoch: 4\n",
            "\tTrain Loss: 289.879 | Train Acc: 74.32%\n",
            "\tTest Loss: 100.419 | Test Acc: 68.75%\n",
            "\n",
            "Epoch: 5\n",
            "\tTrain Loss: 262.232 | Train Acc: 76.73%\n",
            "\tTest Loss: 99.133 | Test Acc: 69.04%\n",
            "\n",
            "Epoch: 6\n",
            "\tTrain Loss: 252.487 | Train Acc: 77.87%\n",
            "\tTest Loss: 73.905 | Test Acc: 76.14%\n",
            "\n",
            "Epoch: 7\n",
            "\tTrain Loss: 241.400 | Train Acc: 78.62%\n",
            "\tTest Loss: 96.964 | Test Acc: 70.64%\n",
            "\n",
            "Epoch: 8\n",
            "\tTrain Loss: 232.773 | Train Acc: 79.77%\n",
            "\tTest Loss: 80.161 | Test Acc: 72.83%\n",
            "\n",
            "Epoch: 9\n",
            "\tTrain Loss: 225.087 | Train Acc: 80.38%\n",
            "\tTest Loss: 65.333 | Test Acc: 77.61%\n",
            "\n",
            "Epoch: 10\n",
            "\tTrain Loss: 221.564 | Train Acc: 80.51%\n",
            "\tTest Loss: 71.124 | Test Acc: 76.90%\n",
            "\n",
            "Epoch: 11\n",
            "\tTrain Loss: 214.180 | Train Acc: 81.15%\n",
            "\tTest Loss: 69.519 | Test Acc: 77.84%\n",
            "\n",
            "Epoch: 12\n",
            "\tTrain Loss: 208.091 | Train Acc: 81.84%\n",
            "\tTest Loss: 61.686 | Test Acc: 80.34%\n",
            "\n",
            "Epoch: 13\n",
            "\tTrain Loss: 207.159 | Train Acc: 81.76%\n",
            "\tTest Loss: 72.529 | Test Acc: 75.19%\n",
            "\n",
            "Epoch: 14\n",
            "\tTrain Loss: 201.842 | Train Acc: 82.27%\n",
            "\tTest Loss: 83.673 | Test Acc: 73.21%\n",
            "\n",
            "Epoch: 15\n",
            "\tTrain Loss: 199.059 | Train Acc: 82.70%\n",
            "\tTest Loss: 73.686 | Test Acc: 75.40%\n",
            "\n",
            "Epoch: 16\n",
            "\tTrain Loss: 197.982 | Train Acc: 82.81%\n",
            "\tTest Loss: 71.141 | Test Acc: 76.33%\n",
            "\n",
            "Epoch: 17\n",
            "\tTrain Loss: 196.958 | Train Acc: 82.71%\n",
            "\tTest Loss: 58.540 | Test Acc: 80.41%\n",
            "\n",
            "Epoch: 18\n",
            "\tTrain Loss: 191.278 | Train Acc: 83.16%\n",
            "\tTest Loss: 81.526 | Test Acc: 75.03%\n",
            "\n",
            "Epoch: 19\n",
            "\tTrain Loss: 190.381 | Train Acc: 83.25%\n",
            "\tTest Loss: 73.052 | Test Acc: 76.31%\n",
            "\n",
            "Epoch: 20\n",
            "\tTrain Loss: 188.990 | Train Acc: 83.34%\n",
            "\tTest Loss: 65.967 | Test Acc: 78.19%\n",
            "\n",
            "Epoch: 21\n",
            "\tTrain Loss: 187.769 | Train Acc: 83.55%\n",
            "\tTest Loss: 65.507 | Test Acc: 79.14%\n",
            "\n",
            "Epoch: 22\n",
            "\tTrain Loss: 182.655 | Train Acc: 83.91%\n",
            "\tTest Loss: 58.702 | Test Acc: 80.31%\n",
            "\n",
            "Epoch: 23\n",
            "\tTrain Loss: 182.217 | Train Acc: 84.02%\n",
            "\tTest Loss: 75.136 | Test Acc: 76.05%\n",
            "\n",
            "Epoch: 24\n",
            "\tTrain Loss: 184.040 | Train Acc: 83.93%\n",
            "\tTest Loss: 53.183 | Test Acc: 82.05%\n",
            "\n",
            "Epoch: 25\n",
            "\tTrain Loss: 182.473 | Train Acc: 83.98%\n",
            "\tTest Loss: 59.942 | Test Acc: 80.47%\n",
            "\n",
            "Epoch: 26\n",
            "\tTrain Loss: 179.033 | Train Acc: 84.32%\n",
            "\tTest Loss: 62.640 | Test Acc: 79.88%\n",
            "\n",
            "Epoch: 27\n",
            "\tTrain Loss: 178.165 | Train Acc: 84.41%\n",
            "\tTest Loss: 87.741 | Test Acc: 74.01%\n",
            "\n",
            "Epoch: 28\n",
            "\tTrain Loss: 175.275 | Train Acc: 84.68%\n",
            "\tTest Loss: 65.268 | Test Acc: 78.51%\n",
            "\n",
            "Epoch: 29\n",
            "\tTrain Loss: 175.450 | Train Acc: 84.60%\n",
            "\tTest Loss: 64.875 | Test Acc: 79.52%\n",
            "\n",
            "Epoch: 30\n",
            "\tTrain Loss: 174.020 | Train Acc: 84.84%\n",
            "\tTest Loss: 60.536 | Test Acc: 79.66%\n",
            "\n",
            "Epoch: 31\n",
            "\tTrain Loss: 173.247 | Train Acc: 84.79%\n",
            "\tTest Loss: 74.295 | Test Acc: 77.91%\n",
            "\n",
            "Epoch: 32\n",
            "\tTrain Loss: 174.785 | Train Acc: 84.58%\n",
            "\tTest Loss: 64.752 | Test Acc: 78.93%\n",
            "\n",
            "Epoch: 33\n",
            "\tTrain Loss: 172.323 | Train Acc: 85.02%\n",
            "\tTest Loss: 68.833 | Test Acc: 78.08%\n",
            "\n",
            "Epoch: 34\n",
            "\tTrain Loss: 175.091 | Train Acc: 84.67%\n",
            "\tTest Loss: 61.095 | Test Acc: 80.00%\n",
            "\n",
            "Epoch: 35\n",
            "\tTrain Loss: 169.239 | Train Acc: 85.21%\n",
            "\tTest Loss: 58.698 | Test Acc: 80.41%\n",
            "\n",
            "Epoch: 36\n",
            "\tTrain Loss: 168.856 | Train Acc: 85.28%\n",
            "\tTest Loss: 86.179 | Test Acc: 74.59%\n",
            "\n",
            "Epoch: 37\n",
            "\tTrain Loss: 168.625 | Train Acc: 85.24%\n",
            "\tTest Loss: 61.302 | Test Acc: 80.23%\n",
            "\n",
            "Epoch: 38\n",
            "\tTrain Loss: 165.881 | Train Acc: 85.47%\n",
            "\tTest Loss: 129.335 | Test Acc: 68.42%\n",
            "\n",
            "Epoch: 39\n",
            "\tTrain Loss: 168.315 | Train Acc: 85.32%\n",
            "\tTest Loss: 77.818 | Test Acc: 77.35%\n",
            "\n",
            "Epoch: 40\n",
            "\tTrain Loss: 162.810 | Train Acc: 85.95%\n",
            "\tTest Loss: 56.337 | Test Acc: 81.55%\n",
            "\n",
            "Epoch: 41\n",
            "\tTrain Loss: 164.075 | Train Acc: 85.76%\n",
            "\tTest Loss: 64.055 | Test Acc: 80.15%\n",
            "\n",
            "Epoch: 42\n",
            "\tTrain Loss: 164.794 | Train Acc: 85.72%\n",
            "\tTest Loss: 58.147 | Test Acc: 80.76%\n",
            "\n",
            "Epoch: 43\n",
            "\tTrain Loss: 162.553 | Train Acc: 85.90%\n",
            "\tTest Loss: 87.748 | Test Acc: 75.55%\n",
            "\n",
            "Epoch: 44\n",
            "\tTrain Loss: 161.923 | Train Acc: 85.82%\n",
            "\tTest Loss: 63.863 | Test Acc: 79.66%\n",
            "\n",
            "Epoch: 45\n",
            "\tTrain Loss: 160.393 | Train Acc: 85.82%\n",
            "\tTest Loss: 69.250 | Test Acc: 78.89%\n",
            "\n",
            "Epoch: 46\n",
            "\tTrain Loss: 162.620 | Train Acc: 85.85%\n",
            "\tTest Loss: 63.826 | Test Acc: 79.63%\n",
            "\n",
            "Epoch: 47\n",
            "\tTrain Loss: 157.275 | Train Acc: 86.34%\n",
            "\tTest Loss: 68.657 | Test Acc: 77.83%\n",
            "\n",
            "Epoch: 48\n",
            "\tTrain Loss: 158.626 | Train Acc: 86.09%\n",
            "\tTest Loss: 55.782 | Test Acc: 81.13%\n",
            "\n",
            "Epoch: 49\n",
            "\tTrain Loss: 158.819 | Train Acc: 86.31%\n",
            "\tTest Loss: 54.880 | Test Acc: 81.59%\n",
            "num_blocks=[1, 3, 0, 1]\n",
            "Will train model with 4608330  parameters\n",
            "\n",
            "Epoch: 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/torchinfo/torchinfo.py:477: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  action_fn=lambda data: sys.getsizeof(data.storage()),\n",
            "/usr/local/lib/python3.9/dist-packages/torch/storage.py:665: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  return super().__sizeof__() + self.nbytes()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss: 604.581 | Train Acc: 42.92%\n",
            "\tTest Loss: 129.093 | Test Acc: 53.72%\n",
            "\n",
            "Epoch: 1\n",
            "\tTrain Loss: 418.499 | Train Acc: 61.75%\n",
            "\tTest Loss: 102.836 | Test Acc: 64.62%\n",
            "\n",
            "Epoch: 2\n",
            "\tTrain Loss: 334.710 | Train Acc: 69.49%\n",
            "\tTest Loss: 89.633 | Test Acc: 69.19%\n",
            "\n",
            "Epoch: 3\n",
            "\tTrain Loss: 286.904 | Train Acc: 74.32%\n",
            "\tTest Loss: 79.246 | Test Acc: 72.83%\n",
            "\n",
            "Epoch: 4\n",
            "\tTrain Loss: 257.535 | Train Acc: 77.04%\n",
            "\tTest Loss: 83.723 | Test Acc: 71.31%\n",
            "\n",
            "Epoch: 5\n",
            "\tTrain Loss: 238.858 | Train Acc: 78.90%\n",
            "\tTest Loss: 73.026 | Test Acc: 75.18%\n",
            "\n",
            "Epoch: 6\n",
            "\tTrain Loss: 224.751 | Train Acc: 80.16%\n",
            "\tTest Loss: 80.229 | Test Acc: 73.04%\n",
            "\n",
            "Epoch: 7\n",
            "\tTrain Loss: 214.047 | Train Acc: 81.24%\n",
            "\tTest Loss: 62.387 | Test Acc: 78.27%\n",
            "\n",
            "Epoch: 8\n",
            "\tTrain Loss: 206.256 | Train Acc: 81.83%\n",
            "\tTest Loss: 71.920 | Test Acc: 76.36%\n",
            "\n",
            "Epoch: 9\n",
            "\tTrain Loss: 199.204 | Train Acc: 82.68%\n",
            "\tTest Loss: 126.524 | Test Acc: 66.47%\n",
            "\n",
            "Epoch: 10\n",
            "\tTrain Loss: 191.068 | Train Acc: 83.28%\n",
            "\tTest Loss: 86.433 | Test Acc: 73.76%\n",
            "\n",
            "Epoch: 11\n",
            "\tTrain Loss: 186.982 | Train Acc: 83.73%\n",
            "\tTest Loss: 83.993 | Test Acc: 73.22%\n",
            "\n",
            "Epoch: 12\n",
            "\tTrain Loss: 183.361 | Train Acc: 84.06%\n",
            "\tTest Loss: 61.050 | Test Acc: 79.03%\n",
            "\n",
            "Epoch: 13\n",
            "\tTrain Loss: 178.469 | Train Acc: 84.39%\n",
            "\tTest Loss: 54.020 | Test Acc: 82.27%\n",
            "\n",
            "Epoch: 14\n",
            "\tTrain Loss: 175.618 | Train Acc: 84.56%\n",
            "\tTest Loss: 56.986 | Test Acc: 80.85%\n",
            "\n",
            "Epoch: 15\n",
            "\tTrain Loss: 173.929 | Train Acc: 84.86%\n",
            "\tTest Loss: 55.291 | Test Acc: 80.94%\n",
            "\n",
            "Epoch: 16\n",
            "\tTrain Loss: 171.799 | Train Acc: 85.09%\n",
            "\tTest Loss: 54.749 | Test Acc: 81.76%\n",
            "\n",
            "Epoch: 17\n",
            "\tTrain Loss: 166.325 | Train Acc: 85.48%\n",
            "\tTest Loss: 74.116 | Test Acc: 77.51%\n",
            "\n",
            "Epoch: 18\n",
            "\tTrain Loss: 165.817 | Train Acc: 85.52%\n",
            "\tTest Loss: 69.166 | Test Acc: 78.03%\n",
            "\n",
            "Epoch: 19\n",
            "\tTrain Loss: 164.017 | Train Acc: 85.63%\n",
            "\tTest Loss: 70.344 | Test Acc: 78.34%\n",
            "\n",
            "Epoch: 20\n",
            "\tTrain Loss: 161.513 | Train Acc: 85.85%\n",
            "\tTest Loss: 57.909 | Test Acc: 81.95%\n",
            "\n",
            "Epoch: 21\n",
            "\tTrain Loss: 161.196 | Train Acc: 85.92%\n",
            "\tTest Loss: 83.380 | Test Acc: 75.17%\n",
            "\n",
            "Epoch: 22\n",
            "\tTrain Loss: 158.838 | Train Acc: 86.17%\n",
            "\tTest Loss: 77.948 | Test Acc: 76.19%\n",
            "\n",
            "Epoch: 23\n",
            "\tTrain Loss: 157.983 | Train Acc: 86.24%\n",
            "\tTest Loss: 54.747 | Test Acc: 82.14%\n",
            "\n",
            "Epoch: 24\n",
            "\tTrain Loss: 156.949 | Train Acc: 86.42%\n",
            "\tTest Loss: 49.806 | Test Acc: 83.45%\n",
            "\n",
            "Epoch: 25\n",
            "\tTrain Loss: 156.110 | Train Acc: 86.39%\n",
            "\tTest Loss: 75.316 | Test Acc: 76.80%\n",
            "\n",
            "Epoch: 26\n",
            "\tTrain Loss: 155.161 | Train Acc: 86.46%\n",
            "\tTest Loss: 56.590 | Test Acc: 82.04%\n",
            "\n",
            "Epoch: 27\n",
            "\tTrain Loss: 153.360 | Train Acc: 86.57%\n",
            "\tTest Loss: 61.214 | Test Acc: 80.45%\n",
            "\n",
            "Epoch: 28\n",
            "\tTrain Loss: 152.722 | Train Acc: 86.74%\n",
            "\tTest Loss: 60.095 | Test Acc: 80.69%\n",
            "\n",
            "Epoch: 29\n",
            "\tTrain Loss: 154.136 | Train Acc: 86.56%\n",
            "\tTest Loss: 55.042 | Test Acc: 82.41%\n",
            "\n",
            "Epoch: 30\n",
            "\tTrain Loss: 150.262 | Train Acc: 86.64%\n",
            "\tTest Loss: 56.598 | Test Acc: 81.43%\n",
            "\n",
            "Epoch: 31\n",
            "\tTrain Loss: 148.652 | Train Acc: 86.96%\n",
            "\tTest Loss: 48.609 | Test Acc: 84.10%\n",
            "\n",
            "Epoch: 32\n",
            "\tTrain Loss: 150.483 | Train Acc: 86.86%\n",
            "\tTest Loss: 50.676 | Test Acc: 83.23%\n",
            "\n",
            "Epoch: 33\n",
            "\tTrain Loss: 147.734 | Train Acc: 87.30%\n",
            "\tTest Loss: 58.458 | Test Acc: 81.74%\n",
            "\n",
            "Epoch: 34\n",
            "\tTrain Loss: 149.720 | Train Acc: 86.91%\n",
            "\tTest Loss: 55.341 | Test Acc: 82.31%\n",
            "\n",
            "Epoch: 35\n",
            "\tTrain Loss: 146.372 | Train Acc: 87.31%\n",
            "\tTest Loss: 53.726 | Test Acc: 82.11%\n",
            "\n",
            "Epoch: 36\n",
            "\tTrain Loss: 144.151 | Train Acc: 87.46%\n",
            "\tTest Loss: 55.741 | Test Acc: 81.88%\n",
            "\n",
            "Epoch: 37\n",
            "\tTrain Loss: 143.826 | Train Acc: 87.34%\n",
            "\tTest Loss: 67.422 | Test Acc: 79.66%\n",
            "\n",
            "Epoch: 38\n",
            "\tTrain Loss: 145.138 | Train Acc: 87.43%\n",
            "\tTest Loss: 63.484 | Test Acc: 79.99%\n",
            "\n",
            "Epoch: 39\n",
            "\tTrain Loss: 143.574 | Train Acc: 87.45%\n",
            "\tTest Loss: 64.589 | Test Acc: 79.20%\n",
            "\n",
            "Epoch: 40\n",
            "\tTrain Loss: 142.432 | Train Acc: 87.58%\n",
            "\tTest Loss: 49.130 | Test Acc: 83.55%\n",
            "\n",
            "Epoch: 41\n",
            "\tTrain Loss: 144.069 | Train Acc: 87.30%\n",
            "\tTest Loss: 68.130 | Test Acc: 79.53%\n",
            "\n",
            "Epoch: 42\n",
            "\tTrain Loss: 142.316 | Train Acc: 87.61%\n",
            "\tTest Loss: 65.657 | Test Acc: 79.71%\n",
            "\n",
            "Epoch: 43\n",
            "\tTrain Loss: 141.412 | Train Acc: 87.60%\n",
            "\tTest Loss: 44.510 | Test Acc: 85.59%\n",
            "\n",
            "Epoch: 44\n",
            "\tTrain Loss: 137.585 | Train Acc: 87.80%\n",
            "\tTest Loss: 50.117 | Test Acc: 83.73%\n",
            "\n",
            "Epoch: 45\n",
            "\tTrain Loss: 140.605 | Train Acc: 87.75%\n",
            "\tTest Loss: 58.209 | Test Acc: 82.08%\n",
            "\n",
            "Epoch: 46\n",
            "\tTrain Loss: 138.611 | Train Acc: 87.80%\n",
            "\tTest Loss: 46.674 | Test Acc: 84.66%\n",
            "\n",
            "Epoch: 47\n",
            "\tTrain Loss: 138.845 | Train Acc: 87.84%\n",
            "\tTest Loss: 68.183 | Test Acc: 77.91%\n",
            "\n",
            "Epoch: 48\n",
            "\tTrain Loss: 137.522 | Train Acc: 87.90%\n",
            "\tTest Loss: 79.024 | Test Acc: 76.98%\n",
            "\n",
            "Epoch: 49\n",
            "\tTrain Loss: 137.481 | Train Acc: 88.10%\n",
            "\tTest Loss: 74.715 | Test Acc: 77.47%\n",
            "num_blocks=[1, 3, 1, 0]\n",
            "Will train model with 1953098  parameters\n",
            "\n",
            "Epoch: 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/torchinfo/torchinfo.py:477: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  action_fn=lambda data: sys.getsizeof(data.storage()),\n",
            "/usr/local/lib/python3.9/dist-packages/torch/storage.py:665: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  return super().__sizeof__() + self.nbytes()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss: 607.965 | Train Acc: 42.03%\n",
            "\tTest Loss: 128.680 | Test Acc: 54.41%\n",
            "\n",
            "Epoch: 1\n",
            "\tTrain Loss: 425.684 | Train Acc: 60.73%\n",
            "\tTest Loss: 97.306 | Test Acc: 65.46%\n",
            "\n",
            "Epoch: 2\n",
            "\tTrain Loss: 342.515 | Train Acc: 69.00%\n",
            "\tTest Loss: 94.110 | Test Acc: 67.54%\n",
            "\n",
            "Epoch: 3\n",
            "\tTrain Loss: 291.409 | Train Acc: 74.04%\n",
            "\tTest Loss: 98.416 | Test Acc: 67.38%\n",
            "\n",
            "Epoch: 4\n",
            "\tTrain Loss: 256.977 | Train Acc: 77.27%\n",
            "\tTest Loss: 93.719 | Test Acc: 70.52%\n",
            "\n",
            "Epoch: 5\n",
            "\tTrain Loss: 237.686 | Train Acc: 78.87%\n",
            "\tTest Loss: 75.638 | Test Acc: 74.60%\n",
            "\n",
            "Epoch: 6\n",
            "\tTrain Loss: 223.842 | Train Acc: 80.35%\n",
            "\tTest Loss: 95.758 | Test Acc: 71.66%\n",
            "\n",
            "Epoch: 7\n",
            "\tTrain Loss: 211.952 | Train Acc: 81.36%\n",
            "\tTest Loss: 74.923 | Test Acc: 74.98%\n",
            "\n",
            "Epoch: 8\n",
            "\tTrain Loss: 207.155 | Train Acc: 81.85%\n",
            "\tTest Loss: 67.255 | Test Acc: 77.18%\n",
            "\n",
            "Epoch: 9\n",
            "\tTrain Loss: 197.088 | Train Acc: 82.71%\n",
            "\tTest Loss: 89.093 | Test Acc: 72.75%\n",
            "\n",
            "Epoch: 10\n",
            "\tTrain Loss: 190.219 | Train Acc: 83.17%\n",
            "\tTest Loss: 79.747 | Test Acc: 75.48%\n",
            "\n",
            "Epoch: 11\n",
            "\tTrain Loss: 184.883 | Train Acc: 83.85%\n",
            "\tTest Loss: 109.678 | Test Acc: 69.41%\n",
            "\n",
            "Epoch: 12\n",
            "\tTrain Loss: 182.427 | Train Acc: 84.00%\n",
            "\tTest Loss: 49.917 | Test Acc: 83.05%\n",
            "\n",
            "Epoch: 13\n",
            "\tTrain Loss: 176.192 | Train Acc: 84.39%\n",
            "\tTest Loss: 68.575 | Test Acc: 78.00%\n",
            "\n",
            "Epoch: 14\n",
            "\tTrain Loss: 175.650 | Train Acc: 84.36%\n",
            "\tTest Loss: 58.536 | Test Acc: 80.29%\n",
            "\n",
            "Epoch: 15\n",
            "\tTrain Loss: 170.016 | Train Acc: 85.20%\n",
            "\tTest Loss: 77.704 | Test Acc: 76.09%\n",
            "\n",
            "Epoch: 16\n",
            "\tTrain Loss: 167.770 | Train Acc: 85.27%\n",
            "\tTest Loss: 68.613 | Test Acc: 77.90%\n",
            "\n",
            "Epoch: 17\n",
            "\tTrain Loss: 162.959 | Train Acc: 85.67%\n",
            "\tTest Loss: 51.812 | Test Acc: 82.54%\n",
            "\n",
            "Epoch: 18\n",
            "\tTrain Loss: 162.760 | Train Acc: 85.72%\n",
            "\tTest Loss: 49.256 | Test Acc: 83.50%\n",
            "\n",
            "Epoch: 19\n",
            "\tTrain Loss: 160.705 | Train Acc: 85.89%\n",
            "\tTest Loss: 82.881 | Test Acc: 75.27%\n",
            "\n",
            "Epoch: 20\n",
            "\tTrain Loss: 159.584 | Train Acc: 86.10%\n",
            "\tTest Loss: 60.479 | Test Acc: 80.31%\n",
            "\n",
            "Epoch: 21\n",
            "\tTrain Loss: 157.874 | Train Acc: 86.10%\n",
            "\tTest Loss: 71.891 | Test Acc: 77.55%\n",
            "\n",
            "Epoch: 22\n",
            "\tTrain Loss: 157.171 | Train Acc: 86.29%\n",
            "\tTest Loss: 58.445 | Test Acc: 81.27%\n",
            "\n",
            "Epoch: 23\n",
            "\tTrain Loss: 154.623 | Train Acc: 86.41%\n",
            "\tTest Loss: 55.856 | Test Acc: 81.88%\n",
            "\n",
            "Epoch: 24\n",
            "\tTrain Loss: 151.650 | Train Acc: 86.59%\n",
            "\tTest Loss: 65.367 | Test Acc: 79.94%\n",
            "\n",
            "Epoch: 25\n",
            "\tTrain Loss: 151.783 | Train Acc: 86.83%\n",
            "\tTest Loss: 59.648 | Test Acc: 80.61%\n",
            "\n",
            "Epoch: 26\n",
            "\tTrain Loss: 148.041 | Train Acc: 86.98%\n",
            "\tTest Loss: 58.717 | Test Acc: 81.14%\n",
            "\n",
            "Epoch: 27\n",
            "\tTrain Loss: 150.023 | Train Acc: 86.96%\n",
            "\tTest Loss: 59.608 | Test Acc: 80.89%\n",
            "\n",
            "Epoch: 28\n",
            "\tTrain Loss: 150.291 | Train Acc: 86.93%\n",
            "\tTest Loss: 62.722 | Test Acc: 79.90%\n",
            "\n",
            "Epoch: 29\n",
            "\tTrain Loss: 146.962 | Train Acc: 87.13%\n",
            "\tTest Loss: 82.671 | Test Acc: 76.66%\n",
            "\n",
            "Epoch: 30\n",
            "\tTrain Loss: 147.509 | Train Acc: 87.15%\n",
            "\tTest Loss: 59.317 | Test Acc: 81.31%\n",
            "\n",
            "Epoch: 31\n",
            "\tTrain Loss: 145.457 | Train Acc: 87.42%\n",
            "\tTest Loss: 54.299 | Test Acc: 82.28%\n",
            "\n",
            "Epoch: 32\n",
            "\tTrain Loss: 144.835 | Train Acc: 87.37%\n",
            "\tTest Loss: 58.374 | Test Acc: 81.56%\n",
            "\n",
            "Epoch: 33\n",
            "\tTrain Loss: 139.774 | Train Acc: 87.79%\n",
            "\tTest Loss: 65.833 | Test Acc: 78.99%\n",
            "\n",
            "Epoch: 34\n",
            "\tTrain Loss: 144.180 | Train Acc: 87.50%\n",
            "\tTest Loss: 60.426 | Test Acc: 81.05%\n",
            "\n",
            "Epoch: 35\n",
            "\tTrain Loss: 141.716 | Train Acc: 87.48%\n",
            "\tTest Loss: 60.006 | Test Acc: 81.81%\n",
            "\n",
            "Epoch: 36\n",
            "\tTrain Loss: 142.216 | Train Acc: 87.34%\n",
            "\tTest Loss: 51.734 | Test Acc: 82.47%\n",
            "\n",
            "Epoch: 37\n",
            "\tTrain Loss: 139.842 | Train Acc: 87.82%\n",
            "\tTest Loss: 65.539 | Test Acc: 78.59%\n",
            "\n",
            "Epoch: 38\n",
            "\tTrain Loss: 139.162 | Train Acc: 87.81%\n",
            "\tTest Loss: 58.208 | Test Acc: 81.63%\n",
            "\n",
            "Epoch: 39\n",
            "\tTrain Loss: 136.876 | Train Acc: 88.01%\n",
            "\tTest Loss: 55.824 | Test Acc: 82.99%\n",
            "\n",
            "Epoch: 40\n",
            "\tTrain Loss: 138.297 | Train Acc: 87.81%\n",
            "\tTest Loss: 54.656 | Test Acc: 83.23%\n",
            "\n",
            "Epoch: 41\n",
            "\tTrain Loss: 137.073 | Train Acc: 87.96%\n",
            "\tTest Loss: 67.094 | Test Acc: 79.08%\n",
            "\n",
            "Epoch: 42\n",
            "\tTrain Loss: 134.523 | Train Acc: 88.27%\n",
            "\tTest Loss: 77.191 | Test Acc: 77.35%\n",
            "\n",
            "Epoch: 43\n",
            "\tTrain Loss: 134.401 | Train Acc: 88.16%\n",
            "\tTest Loss: 55.851 | Test Acc: 81.61%\n",
            "\n",
            "Epoch: 44\n",
            "\tTrain Loss: 134.703 | Train Acc: 88.18%\n",
            "\tTest Loss: 50.395 | Test Acc: 83.49%\n",
            "\n",
            "Epoch: 45\n",
            "\tTrain Loss: 134.696 | Train Acc: 88.15%\n",
            "\tTest Loss: 59.870 | Test Acc: 81.98%\n",
            "\n",
            "Epoch: 46\n",
            "\tTrain Loss: 131.646 | Train Acc: 88.52%\n",
            "\tTest Loss: 48.726 | Test Acc: 84.26%\n",
            "\n",
            "Epoch: 47\n",
            "\tTrain Loss: 131.066 | Train Acc: 88.56%\n",
            "\tTest Loss: 51.833 | Test Acc: 82.59%\n",
            "\n",
            "Epoch: 48\n",
            "\tTrain Loss: 130.708 | Train Acc: 88.60%\n",
            "\tTest Loss: 61.051 | Test Acc: 80.41%\n",
            "\n",
            "Epoch: 49\n",
            "\tTrain Loss: 129.135 | Train Acc: 88.75%\n",
            "\tTest Loss: 46.082 | Test Acc: 85.34%\n",
            "num_blocks=[1, 3, 1, 1]\n",
            "Model has too many parameters (5494090), will skip\n",
            "num_blocks=[1, 3, 2, 0]\n",
            "Will train model with 3133770  parameters\n",
            "\n",
            "Epoch: 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/torchinfo/torchinfo.py:477: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  action_fn=lambda data: sys.getsizeof(data.storage()),\n",
            "/usr/local/lib/python3.9/dist-packages/torch/storage.py:665: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  return super().__sizeof__() + self.nbytes()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss: 612.912 | Train Acc: 41.83%\n",
            "\tTest Loss: 128.139 | Test Acc: 54.27%\n",
            "\n",
            "Epoch: 1\n",
            "\tTrain Loss: 427.453 | Train Acc: 60.81%\n",
            "\tTest Loss: 107.843 | Test Acc: 62.14%\n",
            "\n",
            "Epoch: 2\n",
            "\tTrain Loss: 332.986 | Train Acc: 69.91%\n",
            "\tTest Loss: 87.448 | Test Acc: 70.67%\n",
            "\n",
            "Epoch: 3\n",
            "\tTrain Loss: 279.888 | Train Acc: 75.06%\n",
            "\tTest Loss: 104.718 | Test Acc: 68.66%\n",
            "\n",
            "Epoch: 4\n",
            "\tTrain Loss: 245.948 | Train Acc: 78.28%\n",
            "\tTest Loss: 64.820 | Test Acc: 78.16%\n",
            "\n",
            "Epoch: 5\n",
            "\tTrain Loss: 224.103 | Train Acc: 80.12%\n",
            "\tTest Loss: 66.321 | Test Acc: 77.89%\n",
            "\n",
            "Epoch: 6\n",
            "\tTrain Loss: 210.410 | Train Acc: 81.69%\n",
            "\tTest Loss: 103.771 | Test Acc: 69.31%\n",
            "\n",
            "Epoch: 7\n",
            "\tTrain Loss: 202.172 | Train Acc: 82.31%\n",
            "\tTest Loss: 67.518 | Test Acc: 77.49%\n",
            "\n",
            "Epoch: 8\n",
            "\tTrain Loss: 191.347 | Train Acc: 83.29%\n",
            "\tTest Loss: 54.636 | Test Acc: 81.34%\n",
            "\n",
            "Epoch: 9\n",
            "\tTrain Loss: 182.096 | Train Acc: 83.95%\n",
            "\tTest Loss: 67.097 | Test Acc: 78.43%\n",
            "\n",
            "Epoch: 10\n",
            "\tTrain Loss: 178.285 | Train Acc: 84.60%\n",
            "\tTest Loss: 77.268 | Test Acc: 76.32%\n",
            "\n",
            "Epoch: 11\n",
            "\tTrain Loss: 171.478 | Train Acc: 84.93%\n",
            "\tTest Loss: 51.636 | Test Acc: 82.70%\n",
            "\n",
            "Epoch: 12\n",
            "\tTrain Loss: 168.622 | Train Acc: 85.25%\n",
            "\tTest Loss: 108.229 | Test Acc: 71.32%\n",
            "\n",
            "Epoch: 13\n",
            "\tTrain Loss: 162.257 | Train Acc: 85.86%\n",
            "\tTest Loss: 67.364 | Test Acc: 79.09%\n",
            "\n",
            "Epoch: 14\n",
            "\tTrain Loss: 160.732 | Train Acc: 85.96%\n",
            "\tTest Loss: 61.043 | Test Acc: 80.60%\n",
            "\n",
            "Epoch: 15\n",
            "\tTrain Loss: 154.620 | Train Acc: 86.47%\n",
            "\tTest Loss: 57.506 | Test Acc: 81.92%\n",
            "\n",
            "Epoch: 16\n",
            "\tTrain Loss: 151.967 | Train Acc: 86.74%\n",
            "\tTest Loss: 58.150 | Test Acc: 80.95%\n",
            "\n",
            "Epoch: 17\n",
            "\tTrain Loss: 150.606 | Train Acc: 86.82%\n",
            "\tTest Loss: 84.755 | Test Acc: 75.55%\n",
            "\n",
            "Epoch: 18\n",
            "\tTrain Loss: 148.377 | Train Acc: 87.16%\n",
            "\tTest Loss: 60.896 | Test Acc: 81.10%\n",
            "\n",
            "Epoch: 19\n",
            "\tTrain Loss: 146.848 | Train Acc: 87.12%\n",
            "\tTest Loss: 67.002 | Test Acc: 80.08%\n",
            "\n",
            "Epoch: 20\n",
            "\tTrain Loss: 144.138 | Train Acc: 87.44%\n",
            "\tTest Loss: 44.908 | Test Acc: 85.07%\n",
            "\n",
            "Epoch: 21\n",
            "\tTrain Loss: 140.427 | Train Acc: 87.70%\n",
            "\tTest Loss: 65.702 | Test Acc: 80.04%\n",
            "\n",
            "Epoch: 22\n",
            "\tTrain Loss: 142.122 | Train Acc: 87.60%\n",
            "\tTest Loss: 58.381 | Test Acc: 81.67%\n",
            "\n",
            "Epoch: 23\n",
            "\tTrain Loss: 139.376 | Train Acc: 87.79%\n",
            "\tTest Loss: 50.338 | Test Acc: 83.48%\n",
            "\n",
            "Epoch: 24\n",
            "\tTrain Loss: 136.743 | Train Acc: 88.09%\n",
            "\tTest Loss: 50.194 | Test Acc: 83.74%\n",
            "\n",
            "Epoch: 25\n",
            "\tTrain Loss: 135.855 | Train Acc: 88.07%\n",
            "\tTest Loss: 54.108 | Test Acc: 81.99%\n",
            "\n",
            "Epoch: 26\n",
            "\tTrain Loss: 136.524 | Train Acc: 88.10%\n",
            "\tTest Loss: 52.087 | Test Acc: 83.56%\n",
            "\n",
            "Epoch: 27\n",
            "\tTrain Loss: 133.048 | Train Acc: 88.45%\n",
            "\tTest Loss: 43.532 | Test Acc: 85.83%\n",
            "\n",
            "Epoch: 28\n",
            "\tTrain Loss: 135.450 | Train Acc: 88.09%\n",
            "\tTest Loss: 56.109 | Test Acc: 82.63%\n",
            "\n",
            "Epoch: 29\n",
            "\tTrain Loss: 131.391 | Train Acc: 88.53%\n",
            "\tTest Loss: 62.275 | Test Acc: 80.68%\n",
            "\n",
            "Epoch: 30\n",
            "\tTrain Loss: 131.583 | Train Acc: 88.49%\n",
            "\tTest Loss: 57.681 | Test Acc: 82.07%\n",
            "\n",
            "Epoch: 31\n",
            "\tTrain Loss: 131.028 | Train Acc: 88.55%\n",
            "\tTest Loss: 44.140 | Test Acc: 85.46%\n",
            "\n",
            "Epoch: 32\n",
            "\tTrain Loss: 129.899 | Train Acc: 88.64%\n",
            "\tTest Loss: 47.285 | Test Acc: 84.44%\n",
            "\n",
            "Epoch: 33\n",
            "\tTrain Loss: 129.267 | Train Acc: 88.57%\n",
            "\tTest Loss: 67.647 | Test Acc: 80.42%\n",
            "\n",
            "Epoch: 34\n",
            "\tTrain Loss: 127.018 | Train Acc: 88.78%\n",
            "\tTest Loss: 51.984 | Test Acc: 83.38%\n",
            "\n",
            "Epoch: 35\n",
            "\tTrain Loss: 126.412 | Train Acc: 88.85%\n",
            "\tTest Loss: 42.883 | Test Acc: 85.52%\n",
            "\n",
            "Epoch: 36\n",
            "\tTrain Loss: 124.197 | Train Acc: 89.11%\n",
            "\tTest Loss: 57.283 | Test Acc: 81.17%\n",
            "\n",
            "Epoch: 37\n",
            "\tTrain Loss: 126.194 | Train Acc: 88.92%\n",
            "\tTest Loss: 56.119 | Test Acc: 82.65%\n",
            "\n",
            "Epoch: 38\n",
            "\tTrain Loss: 124.572 | Train Acc: 89.16%\n",
            "\tTest Loss: 58.513 | Test Acc: 81.09%\n",
            "\n",
            "Epoch: 39\n",
            "\tTrain Loss: 121.490 | Train Acc: 89.43%\n",
            "\tTest Loss: 47.270 | Test Acc: 84.55%\n",
            "\n",
            "Epoch: 40\n",
            "\tTrain Loss: 123.613 | Train Acc: 89.08%\n",
            "\tTest Loss: 60.623 | Test Acc: 80.60%\n",
            "\n",
            "Epoch: 41\n",
            "\tTrain Loss: 122.179 | Train Acc: 89.12%\n",
            "\tTest Loss: 44.535 | Test Acc: 85.56%\n",
            "\n",
            "Epoch: 42\n",
            "\tTrain Loss: 121.591 | Train Acc: 89.31%\n",
            "\tTest Loss: 50.634 | Test Acc: 83.27%\n",
            "\n",
            "Epoch: 43\n",
            "\tTrain Loss: 119.598 | Train Acc: 89.47%\n",
            "\tTest Loss: 42.122 | Test Acc: 86.16%\n",
            "\n",
            "Epoch: 44\n",
            "\tTrain Loss: 120.933 | Train Acc: 89.36%\n",
            "\tTest Loss: 42.600 | Test Acc: 86.06%\n",
            "\n",
            "Epoch: 45\n",
            "\tTrain Loss: 118.424 | Train Acc: 89.66%\n",
            "\tTest Loss: 47.567 | Test Acc: 84.56%\n",
            "\n",
            "Epoch: 46\n",
            "\tTrain Loss: 117.521 | Train Acc: 89.61%\n",
            "\tTest Loss: 50.890 | Test Acc: 84.60%\n",
            "\n",
            "Epoch: 47\n",
            "\tTrain Loss: 119.038 | Train Acc: 89.49%\n",
            "\tTest Loss: 47.040 | Test Acc: 84.49%\n",
            "\n",
            "Epoch: 48\n",
            "\tTrain Loss: 114.861 | Train Acc: 89.87%\n",
            "\tTest Loss: 70.482 | Test Acc: 80.11%\n",
            "\n",
            "Epoch: 49\n",
            "\tTrain Loss: 114.764 | Train Acc: 89.97%\n",
            "\tTest Loss: 48.291 | Test Acc: 84.12%\n",
            "num_blocks=[1, 3, 2, 1]\n",
            "Model has too many parameters (6674762), will skip\n",
            "num_blocks=[2, 1, 0, 0]\n",
            "Will train model with 550474  parameters\n",
            "\n",
            "Epoch: 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/torchinfo/torchinfo.py:477: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  action_fn=lambda data: sys.getsizeof(data.storage()),\n",
            "/usr/local/lib/python3.9/dist-packages/torch/storage.py:665: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  return super().__sizeof__() + self.nbytes()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss: 674.894 | Train Acc: 34.70%\n",
            "\tTest Loss: 155.408 | Test Acc: 41.42%\n",
            "\n",
            "Epoch: 1\n",
            "\tTrain Loss: 548.892 | Train Acc: 48.49%\n",
            "\tTest Loss: 148.025 | Test Acc: 47.95%\n",
            "\n",
            "Epoch: 2\n",
            "\tTrain Loss: 483.555 | Train Acc: 55.25%\n",
            "\tTest Loss: 132.071 | Test Acc: 53.35%\n",
            "\n",
            "Epoch: 3\n",
            "\tTrain Loss: 443.670 | Train Acc: 59.21%\n",
            "\tTest Loss: 138.342 | Test Acc: 52.14%\n",
            "\n",
            "Epoch: 4\n",
            "\tTrain Loss: 414.273 | Train Acc: 62.04%\n",
            "\tTest Loss: 107.252 | Test Acc: 61.57%\n",
            "\n",
            "Epoch: 5\n",
            "\tTrain Loss: 396.447 | Train Acc: 64.16%\n",
            "\tTest Loss: 125.538 | Test Acc: 57.30%\n",
            "\n",
            "Epoch: 6\n",
            "\tTrain Loss: 377.292 | Train Acc: 65.86%\n",
            "\tTest Loss: 111.377 | Test Acc: 61.33%\n",
            "\n",
            "Epoch: 7\n",
            "\tTrain Loss: 366.559 | Train Acc: 67.27%\n",
            "\tTest Loss: 118.327 | Test Acc: 58.77%\n",
            "\n",
            "Epoch: 8\n",
            "\tTrain Loss: 354.224 | Train Acc: 68.20%\n",
            "\tTest Loss: 115.464 | Test Acc: 61.04%\n",
            "\n",
            "Epoch: 9\n",
            "\tTrain Loss: 344.231 | Train Acc: 69.19%\n",
            "\tTest Loss: 108.264 | Test Acc: 63.88%\n",
            "\n",
            "Epoch: 10\n",
            "\tTrain Loss: 336.694 | Train Acc: 69.84%\n",
            "\tTest Loss: 105.465 | Test Acc: 64.31%\n",
            "\n",
            "Epoch: 11\n",
            "\tTrain Loss: 327.209 | Train Acc: 70.86%\n",
            "\tTest Loss: 99.577 | Test Acc: 66.21%\n",
            "\n",
            "Epoch: 12\n",
            "\tTrain Loss: 323.120 | Train Acc: 71.51%\n",
            "\tTest Loss: 114.588 | Test Acc: 63.12%\n",
            "\n",
            "Epoch: 13\n",
            "\tTrain Loss: 319.307 | Train Acc: 71.53%\n",
            "\tTest Loss: 115.352 | Test Acc: 61.91%\n",
            "\n",
            "Epoch: 14\n",
            "\tTrain Loss: 312.522 | Train Acc: 72.22%\n",
            "\tTest Loss: 88.294 | Test Acc: 69.16%\n",
            "\n",
            "Epoch: 15\n",
            "\tTrain Loss: 308.778 | Train Acc: 72.82%\n",
            "\tTest Loss: 93.365 | Test Acc: 68.57%\n",
            "\n",
            "Epoch: 16\n",
            "\tTrain Loss: 306.069 | Train Acc: 72.83%\n",
            "\tTest Loss: 89.422 | Test Acc: 69.58%\n",
            "\n",
            "Epoch: 17\n",
            "\tTrain Loss: 302.059 | Train Acc: 73.29%\n",
            "\tTest Loss: 125.448 | Test Acc: 61.84%\n",
            "\n",
            "Epoch: 18\n",
            "\tTrain Loss: 301.264 | Train Acc: 73.39%\n",
            "\tTest Loss: 142.099 | Test Acc: 58.36%\n",
            "\n",
            "Epoch: 19\n",
            "\tTrain Loss: 296.451 | Train Acc: 73.90%\n",
            "\tTest Loss: 97.046 | Test Acc: 66.29%\n",
            "\n",
            "Epoch: 20\n",
            "\tTrain Loss: 293.287 | Train Acc: 74.10%\n",
            "\tTest Loss: 84.334 | Test Acc: 69.93%\n",
            "\n",
            "Epoch: 21\n",
            "\tTrain Loss: 291.623 | Train Acc: 74.33%\n",
            "\tTest Loss: 112.852 | Test Acc: 64.98%\n",
            "\n",
            "Epoch: 22\n",
            "\tTrain Loss: 292.022 | Train Acc: 74.25%\n",
            "\tTest Loss: 100.682 | Test Acc: 67.44%\n",
            "\n",
            "Epoch: 23\n",
            "\tTrain Loss: 289.279 | Train Acc: 74.47%\n",
            "\tTest Loss: 93.431 | Test Acc: 69.02%\n",
            "\n",
            "Epoch: 24\n",
            "\tTrain Loss: 284.765 | Train Acc: 75.10%\n",
            "\tTest Loss: 90.534 | Test Acc: 70.30%\n",
            "\n",
            "Epoch: 25\n",
            "\tTrain Loss: 284.294 | Train Acc: 75.06%\n",
            "\tTest Loss: 98.752 | Test Acc: 67.19%\n",
            "\n",
            "Epoch: 26\n",
            "\tTrain Loss: 283.786 | Train Acc: 75.01%\n",
            "\tTest Loss: 107.330 | Test Acc: 66.10%\n",
            "\n",
            "Epoch: 27\n",
            "\tTrain Loss: 282.873 | Train Acc: 75.22%\n",
            "\tTest Loss: 89.057 | Test Acc: 69.83%\n",
            "\n",
            "Epoch: 28\n",
            "\tTrain Loss: 278.007 | Train Acc: 75.64%\n",
            "\tTest Loss: 102.777 | Test Acc: 65.28%\n",
            "\n",
            "Epoch: 29\n",
            "\tTrain Loss: 275.504 | Train Acc: 75.57%\n",
            "\tTest Loss: 119.054 | Test Acc: 63.28%\n",
            "\n",
            "Epoch: 30\n",
            "\tTrain Loss: 276.823 | Train Acc: 75.65%\n",
            "\tTest Loss: 73.062 | Test Acc: 74.80%\n",
            "\n",
            "Epoch: 31\n",
            "\tTrain Loss: 275.720 | Train Acc: 75.65%\n",
            "\tTest Loss: 87.336 | Test Acc: 70.36%\n",
            "\n",
            "Epoch: 32\n",
            "\tTrain Loss: 276.563 | Train Acc: 75.72%\n",
            "\tTest Loss: 101.536 | Test Acc: 68.08%\n",
            "\n",
            "Epoch: 33\n",
            "\tTrain Loss: 274.834 | Train Acc: 75.92%\n",
            "\tTest Loss: 111.105 | Test Acc: 64.60%\n",
            "\n",
            "Epoch: 34\n",
            "\tTrain Loss: 272.169 | Train Acc: 75.95%\n",
            "\tTest Loss: 85.521 | Test Acc: 72.38%\n",
            "\n",
            "Epoch: 35\n",
            "\tTrain Loss: 271.542 | Train Acc: 76.05%\n",
            "\tTest Loss: 98.951 | Test Acc: 68.40%\n",
            "\n",
            "Epoch: 36\n",
            "\tTrain Loss: 270.302 | Train Acc: 76.40%\n",
            "\tTest Loss: 119.232 | Test Acc: 61.50%\n",
            "\n",
            "Epoch: 37\n",
            "\tTrain Loss: 269.165 | Train Acc: 76.10%\n",
            "\tTest Loss: 73.976 | Test Acc: 75.40%\n",
            "\n",
            "Epoch: 38\n",
            "\tTrain Loss: 267.363 | Train Acc: 76.63%\n",
            "\tTest Loss: 119.574 | Test Acc: 63.42%\n",
            "\n",
            "Epoch: 39\n",
            "\tTrain Loss: 266.500 | Train Acc: 76.57%\n",
            "\tTest Loss: 127.241 | Test Acc: 62.09%\n",
            "\n",
            "Epoch: 40\n",
            "\tTrain Loss: 264.902 | Train Acc: 76.91%\n",
            "\tTest Loss: 97.670 | Test Acc: 68.61%\n",
            "\n",
            "Epoch: 41\n",
            "\tTrain Loss: 268.904 | Train Acc: 76.45%\n",
            "\tTest Loss: 81.633 | Test Acc: 71.70%\n",
            "\n",
            "Epoch: 42\n",
            "\tTrain Loss: 264.262 | Train Acc: 76.82%\n",
            "\tTest Loss: 78.377 | Test Acc: 72.15%\n",
            "\n",
            "Epoch: 43\n",
            "\tTrain Loss: 262.688 | Train Acc: 76.71%\n",
            "\tTest Loss: 88.585 | Test Acc: 70.53%\n",
            "\n",
            "Epoch: 44\n",
            "\tTrain Loss: 262.457 | Train Acc: 77.00%\n",
            "\tTest Loss: 71.152 | Test Acc: 76.04%\n",
            "\n",
            "Epoch: 45\n",
            "\tTrain Loss: 263.351 | Train Acc: 76.98%\n",
            "\tTest Loss: 78.947 | Test Acc: 74.17%\n",
            "\n",
            "Epoch: 46\n",
            "\tTrain Loss: 261.429 | Train Acc: 77.11%\n",
            "\tTest Loss: 96.034 | Test Acc: 68.69%\n",
            "\n",
            "Epoch: 47\n",
            "\tTrain Loss: 260.333 | Train Acc: 77.01%\n",
            "\tTest Loss: 96.149 | Test Acc: 67.89%\n",
            "\n",
            "Epoch: 48\n",
            "\tTrain Loss: 260.205 | Train Acc: 76.82%\n",
            "\tTest Loss: 71.894 | Test Acc: 75.64%\n",
            "\n",
            "Epoch: 49\n",
            "\tTrain Loss: 257.616 | Train Acc: 77.52%\n",
            "\tTest Loss: 73.761 | Test Acc: 75.17%\n",
            "num_blocks=[2, 1, 0, 1]\n",
            "Will train model with 4091466  parameters\n",
            "\n",
            "Epoch: 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/torchinfo/torchinfo.py:477: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  action_fn=lambda data: sys.getsizeof(data.storage()),\n",
            "/usr/local/lib/python3.9/dist-packages/torch/storage.py:665: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  return super().__sizeof__() + self.nbytes()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss: 588.607 | Train Acc: 44.69%\n",
            "\tTest Loss: 125.353 | Test Acc: 55.09%\n",
            "\n",
            "Epoch: 1\n",
            "\tTrain Loss: 419.162 | Train Acc: 61.51%\n",
            "\tTest Loss: 123.125 | Test Acc: 57.02%\n",
            "\n",
            "Epoch: 2\n",
            "\tTrain Loss: 346.780 | Train Acc: 68.66%\n",
            "\tTest Loss: 85.911 | Test Acc: 69.83%\n",
            "\n",
            "Epoch: 3\n",
            "\tTrain Loss: 297.298 | Train Acc: 73.14%\n",
            "\tTest Loss: 76.875 | Test Acc: 73.22%\n",
            "\n",
            "Epoch: 4\n",
            "\tTrain Loss: 267.175 | Train Acc: 76.20%\n",
            "\tTest Loss: 74.537 | Test Acc: 74.54%\n",
            "\n",
            "Epoch: 5\n",
            "\tTrain Loss: 244.757 | Train Acc: 78.39%\n",
            "\tTest Loss: 82.728 | Test Acc: 71.36%\n",
            "\n",
            "Epoch: 6\n",
            "\tTrain Loss: 233.753 | Train Acc: 79.43%\n",
            "\tTest Loss: 72.646 | Test Acc: 75.13%\n",
            "\n",
            "Epoch: 7\n",
            "\tTrain Loss: 224.240 | Train Acc: 80.30%\n",
            "\tTest Loss: 105.913 | Test Acc: 67.51%\n",
            "\n",
            "Epoch: 8\n",
            "\tTrain Loss: 218.020 | Train Acc: 80.83%\n",
            "\tTest Loss: 84.643 | Test Acc: 71.16%\n",
            "\n",
            "Epoch: 9\n",
            "\tTrain Loss: 210.811 | Train Acc: 81.37%\n",
            "\tTest Loss: 60.413 | Test Acc: 79.34%\n",
            "\n",
            "Epoch: 10\n",
            "\tTrain Loss: 206.059 | Train Acc: 81.82%\n",
            "\tTest Loss: 81.421 | Test Acc: 73.97%\n",
            "\n",
            "Epoch: 11\n",
            "\tTrain Loss: 198.358 | Train Acc: 82.61%\n",
            "\tTest Loss: 86.753 | Test Acc: 70.71%\n",
            "\n",
            "Epoch: 12\n",
            "\tTrain Loss: 196.560 | Train Acc: 82.72%\n",
            "\tTest Loss: 74.236 | Test Acc: 75.28%\n",
            "\n",
            "Epoch: 13\n",
            "\tTrain Loss: 193.194 | Train Acc: 83.01%\n",
            "\tTest Loss: 58.554 | Test Acc: 80.20%\n",
            "\n",
            "Epoch: 14\n",
            "\tTrain Loss: 190.666 | Train Acc: 83.23%\n",
            "\tTest Loss: 65.706 | Test Acc: 78.04%\n",
            "\n",
            "Epoch: 15\n",
            "\tTrain Loss: 189.539 | Train Acc: 83.40%\n",
            "\tTest Loss: 61.951 | Test Acc: 79.08%\n",
            "\n",
            "Epoch: 16\n",
            "\tTrain Loss: 186.558 | Train Acc: 83.69%\n",
            "\tTest Loss: 73.011 | Test Acc: 75.49%\n",
            "\n",
            "Epoch: 17\n",
            "\tTrain Loss: 183.439 | Train Acc: 83.79%\n",
            "\tTest Loss: 107.466 | Test Acc: 69.03%\n",
            "\n",
            "Epoch: 18\n",
            "\tTrain Loss: 179.832 | Train Acc: 84.23%\n",
            "\tTest Loss: 60.060 | Test Acc: 79.97%\n",
            "\n",
            "Epoch: 19\n",
            "\tTrain Loss: 180.333 | Train Acc: 84.19%\n",
            "\tTest Loss: 65.930 | Test Acc: 78.94%\n",
            "\n",
            "Epoch: 20\n",
            "\tTrain Loss: 179.533 | Train Acc: 84.25%\n",
            "\tTest Loss: 75.638 | Test Acc: 74.74%\n",
            "\n",
            "Epoch: 21\n",
            "\tTrain Loss: 176.537 | Train Acc: 84.56%\n",
            "\tTest Loss: 66.914 | Test Acc: 77.40%\n",
            "\n",
            "Epoch: 22\n",
            "\tTrain Loss: 174.780 | Train Acc: 84.69%\n",
            "\tTest Loss: 56.517 | Test Acc: 80.82%\n",
            "\n",
            "Epoch: 23\n",
            "\tTrain Loss: 171.326 | Train Acc: 85.07%\n",
            "\tTest Loss: 78.833 | Test Acc: 74.28%\n",
            "\n",
            "Epoch: 24\n",
            "\tTrain Loss: 170.933 | Train Acc: 84.86%\n",
            "\tTest Loss: 76.823 | Test Acc: 75.90%\n",
            "\n",
            "Epoch: 25\n",
            "\tTrain Loss: 170.997 | Train Acc: 84.98%\n",
            "\tTest Loss: 96.368 | Test Acc: 71.12%\n",
            "\n",
            "Epoch: 26\n",
            "\tTrain Loss: 168.949 | Train Acc: 85.23%\n",
            "\tTest Loss: 56.473 | Test Acc: 80.47%\n",
            "\n",
            "Epoch: 27\n",
            "\tTrain Loss: 168.772 | Train Acc: 85.07%\n",
            "\tTest Loss: 66.532 | Test Acc: 77.89%\n",
            "\n",
            "Epoch: 28\n",
            "\tTrain Loss: 168.358 | Train Acc: 85.16%\n",
            "\tTest Loss: 64.194 | Test Acc: 78.98%\n",
            "\n",
            "Epoch: 29\n",
            "\tTrain Loss: 167.582 | Train Acc: 85.30%\n",
            "\tTest Loss: 47.850 | Test Acc: 83.26%\n",
            "\n",
            "Epoch: 30\n",
            "\tTrain Loss: 164.101 | Train Acc: 85.60%\n",
            "\tTest Loss: 65.863 | Test Acc: 78.48%\n",
            "\n",
            "Epoch: 31\n",
            "\tTrain Loss: 163.140 | Train Acc: 85.78%\n",
            "\tTest Loss: 58.823 | Test Acc: 79.75%\n",
            "\n",
            "Epoch: 32\n",
            "\tTrain Loss: 168.117 | Train Acc: 85.30%\n",
            "\tTest Loss: 73.545 | Test Acc: 76.24%\n",
            "\n",
            "Epoch: 33\n",
            "\tTrain Loss: 164.002 | Train Acc: 85.57%\n",
            "\tTest Loss: 59.580 | Test Acc: 80.12%\n",
            "\n",
            "Epoch: 34\n",
            "\tTrain Loss: 162.769 | Train Acc: 85.75%\n",
            "\tTest Loss: 56.456 | Test Acc: 82.05%\n",
            "\n",
            "Epoch: 35\n",
            "\tTrain Loss: 163.192 | Train Acc: 85.82%\n",
            "\tTest Loss: 62.663 | Test Acc: 80.30%\n",
            "\n",
            "Epoch: 36\n",
            "\tTrain Loss: 160.998 | Train Acc: 85.83%\n",
            "\tTest Loss: 75.013 | Test Acc: 76.22%\n",
            "\n",
            "Epoch: 37\n",
            "\tTrain Loss: 161.022 | Train Acc: 85.91%\n",
            "\tTest Loss: 56.891 | Test Acc: 81.20%\n",
            "\n",
            "Epoch: 38\n",
            "\tTrain Loss: 159.477 | Train Acc: 86.11%\n",
            "\tTest Loss: 65.770 | Test Acc: 78.58%\n",
            "\n",
            "Epoch: 39\n",
            "\tTrain Loss: 157.255 | Train Acc: 86.18%\n",
            "\tTest Loss: 60.428 | Test Acc: 80.41%\n",
            "\n",
            "Epoch: 40\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Experimenting with stride"
      ],
      "metadata": {
        "id": "QPG85YDu8y37"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OpVsNJbY5lC3"
      },
      "outputs": [],
      "source": [
        "results = {}\n",
        "for layer1stride in range(1, 4):\n",
        "  for layer2stride in range(1, 4):\n",
        "    for layer3stride in range(1, 4):\n",
        "        # Best from previous sweep\n",
        "        num_blocks=[2, 3, 2, 0]\n",
        "\n",
        "        strides=[layer1stride, layer2stride, layer3stride, 2]\n",
        "\n",
        "        net = ResNetModel(Block, num_blocks, strides=strides)\n",
        "        net = net.to(device)\n",
        "        if device == 'cuda':\n",
        "            net = torch.nn.DataParallel(net)\n",
        "            cudnn.benchmark = True\n",
        "        print(f'strides={strides}')\n",
        "\n",
        "        try:\n",
        "            model_summary = summary(net, (128, 3, 32, 32))\n",
        "            n_params = model_summary.trainable_params\n",
        "            if n_params > 5000000:\n",
        "                print(f\"Model has too many parameters ({n_params}), will skip\")\n",
        "                continue\n",
        "            else:\n",
        "                print(f\"Will train model with {n_params}  parameters\")\n",
        "        except:\n",
        "            print(f\"Invalid combination (strides={strides}), will skip. Most likely a dimensionality error.\")\n",
        "            continue\n",
        "\n",
        "        result = train(net)\n",
        "        results[f'strides:{layer1stride}{layer2stride}{layer3stride}'] = result\n",
        "\n",
        "        save_to_excel(parse_results(results, 'validation'), 'WIP_stride_results_val')\n",
        "        save_to_excel(parse_results(results, 'train'), 'WIP_stride_results_train')\n",
        "\n",
        "save_to_excel(parse_results(results, 'validation'), 'stride_results_val')\n",
        "save_to_excel(parse_results(results, 'train'), 'stride_results_train')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Trying different learning rates"
      ],
      "metadata": {
        "id": "UVNCq9ln801x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results = {}\n",
        "learning_rate = 0.02\n",
        "while learning_rate < 0.2:\n",
        "\n",
        "    # Best from previous sweep\n",
        "    num_blocks=[2, 3, 2, 0]\n",
        "    strides=[1,2,2,2]\n",
        "\n",
        "    net = ResNetModel(Block, num_blocks, strides=strides)\n",
        "    net = net.to(device)\n",
        "    if device == 'cuda':\n",
        "        net = torch.nn.DataParallel(net)\n",
        "        cudnn.benchmark = True\n",
        "    print(f'learning rate = {learning_rate}')\n",
        "\n",
        "    result = train(net, LR=learning_rate)\n",
        "    results[f'Learning Rate={learning_rate}'] = result\n",
        "    \n",
        "    learning_rate += 0.02\n",
        "\n",
        "    save_to_excel(parse_results(results, 'validation'), 'WIP_LR_results_val')\n",
        "    save_to_excel(parse_results(results, 'train'), 'WIP_LR_results_train')\n",
        "\n",
        "save_to_excel(parse_results(results, 'validation'), 'LR_results_val')\n",
        "save_to_excel(parse_results(results, 'train'), 'LR_results_train')"
      ],
      "metadata": {
        "id": "kJORycAPcdEm"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}